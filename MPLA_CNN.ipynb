{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya-Patel/Stat598-FinalProject/blob/main/MPLA_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ucb6l_M4z9M0"
      },
      "outputs": [],
      "source": [
        "# Dataset\n",
        "import yfinance as yf\n",
        "\n",
        "# Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pylab as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "mpl.rcParams['figure.dpi'] = 125\n",
        "mpl.rcParams['figure.figsize'] = (10, 5)\n",
        "\n",
        "# Date Manipulation\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "# PyTorch Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# statstical testing, plotting and decompositions\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Set device usage to GPU if available\n",
        "RANDOM_SEED = 42\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "device = tf.device('/device:gpu:1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neural Network Constants\n",
        "TRAINING_EPOCHS = 500\n",
        "BATCH_SIZE = 32\n",
        "NEURON_CT = 256\n",
        "POOL_SZ = 4\n",
        "STRIDES = 1\n",
        "LEARN_RATE = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i3G3XJbK5rfx"
      },
      "outputs": [],
      "source": [
        "start_date = '2020-06-01'\n",
        "end_date = '2023-12-01'\n",
        "etf_ticker = 'MLPA'\n",
        "moving_average_list = []\n",
        "etf_tickers_url = \"https://raw.githubusercontent.com/Aditya-Patel/Stat598-FinalProject/main/mlpa_full-holdings.csv\"\n",
        "crude_oil_stock_url = \"https://raw.githubusercontent.com/Aditya-Patel/Stat598-FinalProject/main/crude%20oil%20spot%20price.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ishurATN5rfx"
      },
      "source": [
        "<h1>Create joint dataset between spot price and ETF Data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baCYAHr95rfy",
        "outputId": "dcf10ad5-e4ce-4e0c-ef59-5bf9bdbae9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "df_holdings = pd.read_csv(etf_tickers_url)\n",
        "df_holdings = df_holdings[(df_holdings['Name'] != 'OTHER PAYABLE & RECEIVABLES') & (df_holdings['Name'] != 'CASH')]\n",
        "df_holdings[f'Market Value ($)'] = df_holdings[f'Market Value ($)'].str.replace(',', '').astype(float)\n",
        "total_market_value = df_holdings[f'Market Value ($)'].sum()\n",
        "df_holdings['Percentage Holdings By Value'] = (df_holdings[f'Market Value ($)'] / total_market_value)\n",
        "\n",
        "df_crude_price = pd.read_csv(crude_oil_stock_url,usecols=[0, 1])\n",
        "df_crude_price['Date'] = pd.to_datetime(df_crude_price['Date'], format='%b %d, %Y')\n",
        "df_crude_price.set_index('Date', inplace=True)\n",
        "df_crude_price.rename(columns={'WTI Barrell Spot Price':'Spot Price'}, inplace=True)\n",
        "df_crude_price['Spot Price'] = df_crude_price['Spot Price'].fillna(method='ffill')\n",
        "\n",
        "all_stocks_data = yf.download(etf_ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Join spot price and etf data\n",
        "all_stocks_data['Ticker'] = etf_ticker\n",
        "all_stocks_data.columns = [f'{etf_ticker}_{col}' if col not in ['Ticker', 'Date'] else col for col in all_stocks_data.columns]\n",
        "all_stocks_data = all_stocks_data.join(df_crude_price, how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTs1m1kq5rfz"
      },
      "source": [
        "<h1>Load all tickers within the ETF</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72BIKTbv5rfz",
        "outputId": "3ec24716-7f92-40d8-8bb1-bccdd87a83f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# load all tickers part of that etf\n",
        "for ticker in df_holdings['Ticker']:\n",
        "    stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    percentage_holding = df_holdings.loc[df_holdings['Ticker'] == ticker, 'Percentage Holdings By Value'].iloc[0]\n",
        "    all_stocks_data[f'{ticker}_Percent_Holding'] = percentage_holding\n",
        "    stock_data.columns = [f'{ticker}_{col}' if col != 'Ticker' else col for col in stock_data.columns]\n",
        "    all_stocks_data = all_stocks_data.join(stock_data, how='outer')\n",
        "\n",
        "all_stocks_data.fillna(0, inplace=True)\n",
        "sum_values = pd.Series(0, index=all_stocks_data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "toQFsizm5rfz",
        "outputId": "0775f345-427d-4b51-a8db-b56d571c9e48"
      },
      "outputs": [],
      "source": [
        "# Get all closing values\n",
        "\n",
        "all_stocks_data[f'{etf_ticker}_Next_Close'] = all_stocks_data[f'{etf_ticker}_Close'].shift(-1)\n",
        "all_stocks_data = all_stocks_data.drop(all_stocks_data.index[-1])\n",
        "close_values = all_stocks_data[[col for col in all_stocks_data.columns if '_Close' in col or col == 'Spot Price' or col == f'{etf_ticker}_Next_Close']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2sOS7vr66HS3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check correlation\n",
        "df = close_values.drop(columns=[f'{etf_ticker}_Next_Close'])\n",
        "sns.heatmap(df.corr(), annot=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the plot of the correlation matrix, we see that most of the stocks are correlated positively with each other with the exception of SMLP, NGL and USDP, which have negative correlation. We expect to see this as a good ETF consists of a variety of tickers to protect against large market swings either way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>Model Development<h1>\n",
        "<h2> A Dense Neural Network is developed in TensorFlow to perform future analysis based on the previous closing price trend. <h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate X and y input datasets - Since we are predicting the next day value, we use the 'Next_Close' as the target value\n",
        "y = close_values[f'{etf_ticker}_Next_Close']\n",
        "X = close_values.drop(columns=[f'{etf_ticker}_Next_Close'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for training and validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=RANDOM_SEED)\n",
        "\n",
        "# Convert to tensors and prefetch\n",
        "train_df = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_df = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "train_df = train_df.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_df = test_df.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 18, 64)            384       \n",
            "                                                                 \n",
            " average_pooling1d (Average  (None, 15, 64)            0         \n",
            " Pooling1D)                                                      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 128)           41088     \n",
            "                                                                 \n",
            " average_pooling1d_1 (Avera  (None, 8, 128)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 4, 256)            164096    \n",
            "                                                                 \n",
            " average_pooling1d_2 (Avera  (None, 1, 256)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1, 256)            65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1, 128)            32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1, 1)              129       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1, 1)              2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 304387 (1.16 MB)\n",
            "Trainable params: 304387 (1.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN - 3 Convolution Layers, 3 Dense Layers\n",
        "model_1 = keras.models.Sequential([\n",
        "    # Convolution Layer\n",
        "    keras.layers.Conv1D(input_shape=(22,1), filters=NEURON_CT/4, kernel_size=(5,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT/2, kernel_size=(5,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT, kernel_size=(5,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    # DNN Layer\n",
        "    keras.layers.Dense(NEURON_CT, activation='relu'),\n",
        "    keras.layers.Dense(NEURON_CT/2, activation='relu'),\n",
        "    keras.layers.Dense(1),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_1.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 14, 64)            640       \n",
            "                                                                 \n",
            " average_pooling1d_3 (Avera  (None, 11, 64)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 4, 256)            131328    \n",
            "                                                                 \n",
            " average_pooling1d_4 (Avera  (None, 1, 256)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1, 256)            65792     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1, 128)            32896     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1, 64)             8256      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238977 (933.50 KB)\n",
            "Trainable params: 238977 (933.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN - 2 Convolution Layers, 4 Dense Layers\n",
        "model_2 = keras.models.Sequential([\n",
        "    # Convolution Layer\n",
        "    keras.layers.Conv1D(input_shape=(22,1), filters=NEURON_CT/4, kernel_size=(9,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT, kernel_size=(8,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    # DNN Layer\n",
        "    keras.layers.Dense(NEURON_CT, activation='relu'),\n",
        "    keras.layers.Dense(NEURON_CT/2, activation='relu'),\n",
        "    keras.layers.Dense(NEURON_CT/4, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_5 (Conv1D)           (None, 20, 32)            128       \n",
            "                                                                 \n",
            " average_pooling1d_5 (Avera  (None, 17, 32)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 15, 64)            6208      \n",
            "                                                                 \n",
            " average_pooling1d_6 (Avera  (None, 12, 64)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 10, 128)           24704     \n",
            "                                                                 \n",
            " average_pooling1d_7 (Avera  (None, 7, 128)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 4, 256)            131328    \n",
            "                                                                 \n",
            " average_pooling1d_8 (Avera  (None, 1, 256)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1, 256)            65792     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1, 1)              257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 228417 (892.25 KB)\n",
            "Trainable params: 228417 (892.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN - 4 Convolution Layers, 2 Dense Layers\n",
        "model_3 = keras.models.Sequential([\n",
        "    # Convolution Layer\n",
        "    keras.layers.Conv1D(input_shape=(22,1), filters=NEURON_CT/8, kernel_size=(3,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT/4, kernel_size=(3,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT/2, kernel_size=(3,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    keras.layers.Conv1D(filters=NEURON_CT, kernel_size=(4,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    # DNN Layer\n",
        "    keras.layers.Dense(NEURON_CT, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_3.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_9 (Conv1D)           (None, 4, 256)            5120      \n",
            "                                                                 \n",
            " average_pooling1d_9 (Avera  (None, 1, 256)            0         \n",
            " gePooling1D)                                                    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1, 256)            65792     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1, 128)            32896     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1, 1)              129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103937 (406.00 KB)\n",
            "Trainable params: 103937 (406.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# CNN - 1 Convolution Layers, 3 Dense Layers\n",
        "model_4 = keras.models.Sequential([\n",
        "    # Convolution Layer\n",
        "    keras.layers.Conv1D(input_shape=(22,1), filters=NEURON_CT, kernel_size=(19,), activation='relu'),\n",
        "    keras.layers.AvgPool1D(pool_size=POOL_SZ, strides=STRIDES, padding='valid'),\n",
        "    # DNN Layer\n",
        "    keras.layers.Dense(NEURON_CT, activation='relu'),\n",
        "    keras.layers.Dense(NEURON_CT/2, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_4.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 1s 15ms/step - loss: 661.0801 - val_loss: 15.9423\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 61.4822 - val_loss: 36.1406\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.7351 - val_loss: 6.3376\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6.7472 - val_loss: 9.1229\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4.1936 - val_loss: 1.4306\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1769 - val_loss: 1.2199\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9988 - val_loss: 1.1901\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8457 - val_loss: 1.2021\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9107 - val_loss: 1.1824\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8569 - val_loss: 1.1634\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8841 - val_loss: 1.3628\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8240 - val_loss: 1.2126\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8144 - val_loss: 1.1588\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9354 - val_loss: 1.1435\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8393 - val_loss: 1.1959\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8318 - val_loss: 1.2760\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.0619 - val_loss: 1.3336\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9607 - val_loss: 1.3813\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8918 - val_loss: 1.1527\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8564 - val_loss: 1.2122\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7345 - val_loss: 1.2069\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9016 - val_loss: 1.1265\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9453 - val_loss: 1.8155\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.2059 - val_loss: 1.1872\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8893 - val_loss: 1.1262\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8152 - val_loss: 1.1226\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7862 - val_loss: 1.3406\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7679 - val_loss: 1.1194\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7052 - val_loss: 1.4362\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7281 - val_loss: 1.0567\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6779 - val_loss: 1.0913\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7245 - val_loss: 1.0504\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6345 - val_loss: 1.1314\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7448 - val_loss: 1.0470\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8174 - val_loss: 1.0551\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2249 - val_loss: 1.2816\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.9563 - val_loss: 1.3089\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6777 - val_loss: 1.4520\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6969 - val_loss: 1.5847\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8135 - val_loss: 1.1012\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7149 - val_loss: 1.2478\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1420 - val_loss: 1.2039\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2453 - val_loss: 1.7578\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6450 - val_loss: 1.0482\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5419 - val_loss: 1.3971\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6871 - val_loss: 1.1157\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7605 - val_loss: 1.2314\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8027 - val_loss: 1.8841\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7858 - val_loss: 1.0259\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5545 - val_loss: 1.0425\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8885 - val_loss: 1.0265\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9912 - val_loss: 1.7598\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5316 - val_loss: 1.2499\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5981 - val_loss: 1.3235\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5906 - val_loss: 1.0148\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5184 - val_loss: 1.0807\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5673 - val_loss: 1.3620\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7357 - val_loss: 1.0361\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8088 - val_loss: 1.0630\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4722 - val_loss: 1.1396\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5197 - val_loss: 1.0828\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6441 - val_loss: 1.2481\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4849 - val_loss: 1.0252\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5428 - val_loss: 1.0629\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8436 - val_loss: 1.3506\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4771 - val_loss: 1.2316\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5882 - val_loss: 1.0192\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5268 - val_loss: 1.0279\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6238 - val_loss: 1.0878\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5164 - val_loss: 1.0133\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7252 - val_loss: 1.4054\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4866 - val_loss: 0.9774\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3466 - val_loss: 1.1543\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4279 - val_loss: 1.0768\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7172 - val_loss: 1.2848\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4754 - val_loss: 1.0259\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5892 - val_loss: 2.4213\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6586 - val_loss: 0.9875\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4609 - val_loss: 1.0169\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3546 - val_loss: 0.9591\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4966 - val_loss: 1.0134\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5405 - val_loss: 0.9914\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4235 - val_loss: 1.2828\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4543 - val_loss: 1.2280\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6879 - val_loss: 1.5531\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8478 - val_loss: 2.7951\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.4561 - val_loss: 1.5792\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6703 - val_loss: 1.5146\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6240 - val_loss: 0.9699\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3099 - val_loss: 0.9272\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3636 - val_loss: 1.5827\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3409 - val_loss: 1.0812\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3006 - val_loss: 0.9597\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2799 - val_loss: 0.9312\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3082 - val_loss: 0.9577\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3647 - val_loss: 1.0638\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3078 - val_loss: 1.1615\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4385 - val_loss: 0.9029\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4767 - val_loss: 1.4033\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5303 - val_loss: 1.1108\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5134 - val_loss: 1.1932\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4324 - val_loss: 1.0321\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4248 - val_loss: 0.9354\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5806 - val_loss: 1.1062\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3767 - val_loss: 0.8962\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2310 - val_loss: 0.8839\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9413 - val_loss: 3.3627\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1632 - val_loss: 0.8647\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2393 - val_loss: 0.9424\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8396 - val_loss: 2.4938\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6745 - val_loss: 2.9189\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6817 - val_loss: 1.4480\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1139 - val_loss: 1.1098\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4469 - val_loss: 0.8499\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4484 - val_loss: 0.9597\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5887 - val_loss: 0.9306\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.4060 - val_loss: 2.9109\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4164 - val_loss: 0.8995\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3096 - val_loss: 0.9770\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2441 - val_loss: 0.8386\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1905 - val_loss: 0.8404\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1529 - val_loss: 1.0125\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3985 - val_loss: 0.8858\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1426 - val_loss: 0.9908\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5073 - val_loss: 0.8287\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1422 - val_loss: 0.8339\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1282 - val_loss: 0.8989\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1345 - val_loss: 0.8840\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1353 - val_loss: 0.8186\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0918 - val_loss: 1.1994\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2459 - val_loss: 0.8229\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0801 - val_loss: 1.0269\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2555 - val_loss: 3.2841\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7070 - val_loss: 1.4445\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1396 - val_loss: 0.9649\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2335 - val_loss: 1.1501\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1676 - val_loss: 0.8246\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4308 - val_loss: 1.1807\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1049 - val_loss: 0.9807\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7707 - val_loss: 2.4026\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5751 - val_loss: 0.9265\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0019 - val_loss: 1.3167\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1840 - val_loss: 0.7887\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0216 - val_loss: 0.9776\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0520 - val_loss: 0.9468\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0701 - val_loss: 0.9946\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1996 - val_loss: 3.3681\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8613 - val_loss: 2.6798\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8212 - val_loss: 1.8734\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3234 - val_loss: 0.7917\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0520 - val_loss: 0.7879\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3891 - val_loss: 0.8910\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9652 - val_loss: 0.7555\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9545 - val_loss: 0.8055\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1404 - val_loss: 0.7495\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3068 - val_loss: 0.7948\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0714 - val_loss: 1.0674\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0590 - val_loss: 0.8121\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1959 - val_loss: 0.9196\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9757 - val_loss: 0.7627\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0859 - val_loss: 1.5644\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3117 - val_loss: 0.9266\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0063 - val_loss: 1.0361\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3190 - val_loss: 1.5113\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6288 - val_loss: 0.9381\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9688 - val_loss: 0.7487\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8936 - val_loss: 0.9034\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8921 - val_loss: 1.0437\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3237 - val_loss: 0.7741\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1571 - val_loss: 1.4000\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4902 - val_loss: 0.8228\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0397 - val_loss: 0.7322\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1510 - val_loss: 1.0676\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0175 - val_loss: 0.7734\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9867 - val_loss: 1.0876\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9373 - val_loss: 0.9265\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2510 - val_loss: 1.0222\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8334 - val_loss: 0.7552\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9838 - val_loss: 1.7729\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0016 - val_loss: 0.7277\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8791 - val_loss: 1.1368\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5719 - val_loss: 0.8024\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.7157 - val_loss: 1.7136\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0658 - val_loss: 1.6792\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2046 - val_loss: 0.6844\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7771 - val_loss: 0.7009\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9492 - val_loss: 1.3437\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8827 - val_loss: 0.6928\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8557 - val_loss: 1.1126\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1440 - val_loss: 0.8611\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8548 - val_loss: 1.2806\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0146 - val_loss: 0.7520\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1198 - val_loss: 1.9561\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6847 - val_loss: 1.0434\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2042 - val_loss: 0.7777\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7960 - val_loss: 0.6876\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9760 - val_loss: 0.6976\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8298 - val_loss: 0.7776\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7460\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0161 - val_loss: 3.1307\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9550 - val_loss: 1.2397\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2416 - val_loss: 0.9300\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8343 - val_loss: 1.0817\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9919 - val_loss: 0.7166\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7202 - val_loss: 0.8841\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8442 - val_loss: 0.7775\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7239 - val_loss: 0.8062\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0863 - val_loss: 0.7574\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1045 - val_loss: 0.7294\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8269 - val_loss: 0.6822\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8081 - val_loss: 0.6572\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.8301\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7992 - val_loss: 2.0196\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9630 - val_loss: 0.6842\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7270 - val_loss: 1.2484\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9306 - val_loss: 2.8207\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8631 - val_loss: 0.8762\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7393 - val_loss: 0.7005\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 1.0453\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7167\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.8156\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0750 - val_loss: 0.7483\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7332 - val_loss: 0.6998\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7330 - val_loss: 1.2370\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7552 - val_loss: 0.7386\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 1.2575\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8021 - val_loss: 1.9012\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2668 - val_loss: 1.7089\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7374 - val_loss: 2.5257\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.0079 - val_loss: 2.9904\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3210 - val_loss: 0.8088\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7554 - val_loss: 0.6939\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8756 - val_loss: 0.8206\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0372 - val_loss: 1.9397\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0905 - val_loss: 1.3794\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8314 - val_loss: 1.2086\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9334 - val_loss: 0.7891\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6465 - val_loss: 0.9361\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6266 - val_loss: 0.6902\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.8594\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7233 - val_loss: 0.9051\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6027 - val_loss: 4.3318\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6389 - val_loss: 1.5913\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1660 - val_loss: 0.9414\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8883 - val_loss: 0.7193\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8360 - val_loss: 0.7749\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6286 - val_loss: 1.1701\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9078 - val_loss: 0.9619\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8176 - val_loss: 1.4518\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8872 - val_loss: 0.6969\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5924 - val_loss: 0.8621\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7774 - val_loss: 1.2982\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7093 - val_loss: 1.4800\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8060 - val_loss: 0.7669\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7360 - val_loss: 0.6868\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6814 - val_loss: 0.6994\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0033 - val_loss: 0.7590\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8009 - val_loss: 1.0466\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6841 - val_loss: 0.7623\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.7062\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7283 - val_loss: 0.6576\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6203 - val_loss: 0.6538\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7763 - val_loss: 1.0207\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8210 - val_loss: 1.2698\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9429 - val_loss: 0.7761\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7463 - val_loss: 0.6666\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.8238\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6406 - val_loss: 1.2892\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7130 - val_loss: 1.2814\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7384 - val_loss: 1.3995\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8133 - val_loss: 0.6623\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8237 - val_loss: 1.2712\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9970 - val_loss: 0.6450\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0606 - val_loss: 0.7567\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7746 - val_loss: 0.6574\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7047 - val_loss: 0.9470\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.7359\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0202 - val_loss: 1.5487\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3237 - val_loss: 0.7404\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2463 - val_loss: 2.6258\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1541 - val_loss: 0.7324\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6051 - val_loss: 0.7094\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5760 - val_loss: 1.0862\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8619 - val_loss: 0.9455\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7163 - val_loss: 1.1633\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.7423\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6220 - val_loss: 0.6695\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6361 - val_loss: 0.6766\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.6615\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5744 - val_loss: 1.1374\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7063 - val_loss: 0.7034\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8383 - val_loss: 1.1637\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8921 - val_loss: 0.6640\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7949 - val_loss: 0.7672\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6168 - val_loss: 0.6332\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7675 - val_loss: 0.7518\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7012 - val_loss: 0.6617\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6146 - val_loss: 1.0078\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7247 - val_loss: 0.7057\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 1.8008\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1202 - val_loss: 1.0719\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0931 - val_loss: 0.6575\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8208 - val_loss: 0.6677\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.8080\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7953 - val_loss: 0.6313\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1280 - val_loss: 0.6441\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.6800\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5542 - val_loss: 0.6524\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5873 - val_loss: 0.7052\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6638 - val_loss: 0.6622\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7454 - val_loss: 0.7388\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1844 - val_loss: 0.9608\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.6377\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5036 - val_loss: 0.7735\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8456 - val_loss: 0.6575\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.7951\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5552 - val_loss: 1.3968\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7266 - val_loss: 0.6876\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9011 - val_loss: 2.4314\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9208 - val_loss: 0.8729\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7834 - val_loss: 0.7272\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8951 - val_loss: 0.6184\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6948\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6416 - val_loss: 0.8868\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8078 - val_loss: 0.7486\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9689 - val_loss: 1.4929\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9664 - val_loss: 1.1656\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9851 - val_loss: 0.6520\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7173 - val_loss: 1.1292\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9468 - val_loss: 0.6236\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7172 - val_loss: 0.7521\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7400 - val_loss: 1.3318\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7773 - val_loss: 1.0734\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6598 - val_loss: 0.6401\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 1.2420\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6548 - val_loss: 1.5322\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5372 - val_loss: 1.6789\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5990 - val_loss: 1.2331\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0647 - val_loss: 1.0671\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5792 - val_loss: 0.9082\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5340 - val_loss: 0.6609\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7106 - val_loss: 1.6567\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.6239\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5860 - val_loss: 2.3340\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1191 - val_loss: 1.1619\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9743 - val_loss: 0.6304\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7867 - val_loss: 1.0682\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9345 - val_loss: 0.6044\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7684 - val_loss: 0.7456\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0117 - val_loss: 1.0827\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6364 - val_loss: 0.9919\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 1.1509\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6038 - val_loss: 0.7531\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.8949\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9230 - val_loss: 0.6882\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4193 - val_loss: 0.6453\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7387 - val_loss: 0.6723\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0905 - val_loss: 0.6822\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.6296\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5718 - val_loss: 0.6163\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5307 - val_loss: 0.6372\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.8259\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6600 - val_loss: 0.6853\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6423 - val_loss: 1.0618\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6424 - val_loss: 0.8231\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5547 - val_loss: 0.7024\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6388 - val_loss: 0.6164\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5601 - val_loss: 0.6489\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6650 - val_loss: 0.6312\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5234 - val_loss: 0.8211\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5973 - val_loss: 0.6190\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.7496\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8322 - val_loss: 0.6633\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6460 - val_loss: 1.3516\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5972 - val_loss: 1.1204\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9378 - val_loss: 0.6153\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9524 - val_loss: 0.8128\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5162 - val_loss: 0.7071\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6668 - val_loss: 0.6129\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7012 - val_loss: 1.2178\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8185 - val_loss: 0.7746\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7887 - val_loss: 1.6118\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 1.1588\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8305 - val_loss: 1.0084\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.6115\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6412 - val_loss: 0.6561\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7426 - val_loss: 0.8194\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6667 - val_loss: 1.2313\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7984 - val_loss: 1.2106\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0624 - val_loss: 0.7203\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1599 - val_loss: 0.5960\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6895 - val_loss: 0.6372\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.7279\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6436 - val_loss: 0.8565\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4684 - val_loss: 0.7114\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5137 - val_loss: 0.6147\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6101 - val_loss: 0.6289\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9752 - val_loss: 2.5848\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0799 - val_loss: 0.6358\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8511 - val_loss: 0.7006\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7950 - val_loss: 0.6361\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 3.1868\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5964 - val_loss: 1.4874\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0046 - val_loss: 0.6026\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1107 - val_loss: 0.7149\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9619 - val_loss: 1.1165\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 0.6444\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.8639\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 1.2235\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.9189\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7137 - val_loss: 0.5969\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4632 - val_loss: 0.6289\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5029 - val_loss: 0.6480\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4918 - val_loss: 0.6458\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.6117\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5413 - val_loss: 0.6698\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7581 - val_loss: 1.1489\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8509 - val_loss: 0.6173\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4977 - val_loss: 0.6467\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 1.6211\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.6500\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4555 - val_loss: 0.5994\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5134 - val_loss: 0.7107\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4883 - val_loss: 0.6095\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4667 - val_loss: 0.7557\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.6080\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4641 - val_loss: 0.6026\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5177 - val_loss: 0.6085\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6160 - val_loss: 0.7449\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4499 - val_loss: 0.7003\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5215 - val_loss: 0.6025\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2605 - val_loss: 2.7040\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7630 - val_loss: 1.6586\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6802 - val_loss: 0.7157\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6036 - val_loss: 1.1210\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8850 - val_loss: 1.0178\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0508 - val_loss: 1.0480\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1100 - val_loss: 1.5516\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9389 - val_loss: 1.2339\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8893 - val_loss: 0.6896\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4921 - val_loss: 0.6285\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4907 - val_loss: 0.6505\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4816 - val_loss: 0.6086\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5380 - val_loss: 0.6003\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5432 - val_loss: 0.7145\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.6090\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5863 - val_loss: 0.5819\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4822 - val_loss: 0.5909\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 1.3580\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0400 - val_loss: 1.8497\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3893 - val_loss: 2.0315\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8227 - val_loss: 0.6167\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5143 - val_loss: 0.7917\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9036 - val_loss: 1.0693\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 1.0532\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1013 - val_loss: 2.8735\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6170 - val_loss: 1.5533\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8112 - val_loss: 0.7058\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4924 - val_loss: 0.7467\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5962 - val_loss: 0.8284\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5136 - val_loss: 0.6031\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4511 - val_loss: 0.9643\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5965 - val_loss: 0.6069\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4782 - val_loss: 0.7409\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8618 - val_loss: 0.9616\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0249 - val_loss: 1.0149\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6212 - val_loss: 0.5908\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4479 - val_loss: 0.5910\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4444 - val_loss: 0.5801\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4587 - val_loss: 0.5886\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5390 - val_loss: 0.6463\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4947 - val_loss: 0.6093\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5623 - val_loss: 1.3930\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5980 - val_loss: 0.6553\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5386 - val_loss: 0.6145\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5271 - val_loss: 0.5918\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4330 - val_loss: 0.6038\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5205 - val_loss: 0.8216\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8340 - val_loss: 1.4150\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2629 - val_loss: 0.7889\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7112 - val_loss: 1.0416\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 1.4890\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0898 - val_loss: 1.6677\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1011 - val_loss: 1.6161\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6575\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 1.0879\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0759 - val_loss: 1.5039\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1643 - val_loss: 1.0816\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4900 - val_loss: 2.0366\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8272 - val_loss: 1.0217\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7359 - val_loss: 0.9325\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6972 - val_loss: 1.4387\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8003 - val_loss: 0.7267\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6424 - val_loss: 0.6108\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4577 - val_loss: 0.6932\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5660 - val_loss: 0.8429\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6757\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 2.0219\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0180 - val_loss: 0.5664\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9157 - val_loss: 1.0070\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 342.0440 - val_loss: 86.7331\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 34.2032 - val_loss: 7.3942\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9.7549 - val_loss: 1.3213\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.2056 - val_loss: 1.3040\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1015 - val_loss: 1.5690\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1033 - val_loss: 1.3311\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0145 - val_loss: 1.3666\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.9153 - val_loss: 1.2219\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8781 - val_loss: 1.2144\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8742 - val_loss: 1.2985\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8210 - val_loss: 1.6697\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8582 - val_loss: 1.1500\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7814 - val_loss: 1.1767\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8359 - val_loss: 1.2661\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8937 - val_loss: 1.3607\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8304 - val_loss: 1.2103\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8285 - val_loss: 1.2434\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6164 - val_loss: 1.1025\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6946 - val_loss: 1.0905\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7406 - val_loss: 1.0787\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7567 - val_loss: 1.2302\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7866 - val_loss: 1.4176\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6584 - val_loss: 1.0827\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7406 - val_loss: 1.0959\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5332 - val_loss: 1.4579\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7421 - val_loss: 1.1142\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5422 - val_loss: 1.0311\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7321 - val_loss: 1.0474\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6313 - val_loss: 1.4797\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6198 - val_loss: 1.0133\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5670 - val_loss: 1.0113\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6193 - val_loss: 1.3914\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5651 - val_loss: 0.9941\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5172 - val_loss: 1.4941\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7006 - val_loss: 1.6239\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4777 - val_loss: 1.0679\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3816 - val_loss: 0.9753\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5360 - val_loss: 1.2905\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4714 - val_loss: 0.9695\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4222 - val_loss: 1.0771\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3513 - val_loss: 0.9591\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6597 - val_loss: 1.4103\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6767 - val_loss: 1.4562\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.3300 - val_loss: 1.2490\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7753 - val_loss: 2.3507\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8722 - val_loss: 1.1394\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7284 - val_loss: 1.3560\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4520 - val_loss: 0.9232\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6500 - val_loss: 0.9141\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4803 - val_loss: 1.0694\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4755 - val_loss: 1.2062\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7884 - val_loss: 0.9169\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6901 - val_loss: 1.1902\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7042 - val_loss: 1.6452\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5244 - val_loss: 1.2665\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5063 - val_loss: 1.4772\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5193 - val_loss: 0.8721\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2014 - val_loss: 0.8835\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2388 - val_loss: 0.8613\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3389 - val_loss: 0.9012\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3145 - val_loss: 1.0717\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4144 - val_loss: 0.8656\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2782 - val_loss: 0.9887\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3086 - val_loss: 1.0412\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4221 - val_loss: 1.1134\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5082 - val_loss: 2.7253\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5860 - val_loss: 2.0952\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4316 - val_loss: 0.8983\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3324 - val_loss: 1.4992\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4875 - val_loss: 0.8154\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4804 - val_loss: 1.1837\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1794 - val_loss: 1.1096\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0922 - val_loss: 1.0395\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0781 - val_loss: 1.0682\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3087 - val_loss: 1.1386\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3281 - val_loss: 0.9485\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0438 - val_loss: 1.2924\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4178 - val_loss: 1.5651\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3940 - val_loss: 1.5429\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1616 - val_loss: 0.7961\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2583 - val_loss: 0.7737\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0462 - val_loss: 0.9628\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0258 - val_loss: 0.8604\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9924 - val_loss: 1.5109\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0976 - val_loss: 1.3073\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1202 - val_loss: 0.7681\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1557 - val_loss: 1.1850\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3452 - val_loss: 1.2043\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1153 - val_loss: 1.1223\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1311 - val_loss: 0.7436\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8636 - val_loss: 0.8331\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8480 - val_loss: 0.9201\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8381 - val_loss: 0.8597\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9160 - val_loss: 0.8305\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1667 - val_loss: 0.7622\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0742 - val_loss: 0.8747\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9149 - val_loss: 1.3867\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6699 - val_loss: 0.7290\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9544 - val_loss: 0.8098\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8891 - val_loss: 1.9100\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9259 - val_loss: 0.8968\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8673 - val_loss: 0.7424\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7737 - val_loss: 0.7013\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9127 - val_loss: 0.7360\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8820 - val_loss: 0.8871\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8419 - val_loss: 1.2485\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0345 - val_loss: 0.7538\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7530 - val_loss: 0.7048\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0645 - val_loss: 2.1483\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6010 - val_loss: 1.1077\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8185 - val_loss: 2.6044\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1964 - val_loss: 0.7005\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9511 - val_loss: 1.0265\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0894 - val_loss: 0.7070\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6618 - val_loss: 2.2210\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7727 - val_loss: 1.4359\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8967 - val_loss: 0.6734\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7865 - val_loss: 0.6685\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7557 - val_loss: 0.6735\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9004 - val_loss: 0.6672\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7804 - val_loss: 0.6901\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7396 - val_loss: 0.7327\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9087 - val_loss: 1.5004\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0852 - val_loss: 0.8194\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8187 - val_loss: 2.8141\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5040 - val_loss: 1.0668\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0262 - val_loss: 0.6584\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8002 - val_loss: 0.7020\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8756 - val_loss: 0.9790\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7633 - val_loss: 0.7900\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8933 - val_loss: 0.6493\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6991 - val_loss: 0.8608\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8341 - val_loss: 0.9649\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7654 - val_loss: 0.6678\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9087 - val_loss: 0.6637\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8598 - val_loss: 0.6658\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7802 - val_loss: 0.9040\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8448 - val_loss: 0.6720\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6754 - val_loss: 1.2195\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1322 - val_loss: 0.8882\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6503 - val_loss: 1.8260\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0728 - val_loss: 1.5959\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0602 - val_loss: 1.5727\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4316 - val_loss: 0.7820\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8230 - val_loss: 0.6940\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6806 - val_loss: 0.6607\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6801 - val_loss: 1.3226\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7924 - val_loss: 0.6377\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6957 - val_loss: 0.7364\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7271 - val_loss: 0.7433\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6498 - val_loss: 0.7054\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7190 - val_loss: 0.6222\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7986 - val_loss: 0.6231\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7166 - val_loss: 0.6305\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7954 - val_loss: 1.4111\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0646 - val_loss: 1.1487\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7027 - val_loss: 0.6639\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6008 - val_loss: 0.6547\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8315 - val_loss: 0.7229\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6049 - val_loss: 1.0993\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7884 - val_loss: 0.6219\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8086 - val_loss: 0.7138\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3696 - val_loss: 0.6350\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7593 - val_loss: 2.9862\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3651 - val_loss: 1.5782\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9632 - val_loss: 1.8974\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0152 - val_loss: 0.9971\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6802 - val_loss: 0.6406\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8210 - val_loss: 0.6069\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6199 - val_loss: 0.7311\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9847 - val_loss: 1.3115\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8859 - val_loss: 0.9635\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8860 - val_loss: 0.7308\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6742 - val_loss: 0.7143\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7295 - val_loss: 1.2916\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9569 - val_loss: 0.7835\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9745 - val_loss: 0.6084\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7411 - val_loss: 0.6304\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6885 - val_loss: 0.7163\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5638 - val_loss: 0.5956\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6595 - val_loss: 1.4309\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3266 - val_loss: 2.1306\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5578 - val_loss: 1.3526\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0656 - val_loss: 2.6972\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4428 - val_loss: 0.7217\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.9112\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7310 - val_loss: 1.0640\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7320 - val_loss: 0.8000\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9908 - val_loss: 0.8907\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9993 - val_loss: 0.6835\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7774 - val_loss: 1.7307\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9001 - val_loss: 0.7568\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6451 - val_loss: 0.7622\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8036 - val_loss: 0.8024\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3449 - val_loss: 1.4989\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5054 - val_loss: 0.5742\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9562 - val_loss: 0.6294\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7059 - val_loss: 0.8190\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5855 - val_loss: 0.5776\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 1.2708\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8910 - val_loss: 1.1615\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8631 - val_loss: 0.5773\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6691 - val_loss: 0.7767\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6899 - val_loss: 0.7341\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6109 - val_loss: 0.5657\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5890 - val_loss: 0.6462\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5652 - val_loss: 0.7861\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7096 - val_loss: 0.9819\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7132 - val_loss: 0.9326\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5143 - val_loss: 0.6141\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7022 - val_loss: 0.5670\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5134 - val_loss: 0.5652\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6445 - val_loss: 1.2514\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7859 - val_loss: 0.9141\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5968 - val_loss: 0.5513\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7484 - val_loss: 0.5824\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7768 - val_loss: 1.3748\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3140 - val_loss: 1.2266\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6752 - val_loss: 0.5996\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5308 - val_loss: 0.6988\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5854 - val_loss: 0.5760\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7505 - val_loss: 0.5784\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9673 - val_loss: 1.0252\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6392 - val_loss: 0.5635\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6259 - val_loss: 0.5707\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4765 - val_loss: 0.7440\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6601 - val_loss: 0.5518\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5143 - val_loss: 0.5660\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.8779\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2428 - val_loss: 0.6090\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5736 - val_loss: 1.0557\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0608 - val_loss: 0.6629\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9208 - val_loss: 0.6675\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9056 - val_loss: 1.7918\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1353 - val_loss: 1.1557\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2118 - val_loss: 0.7365\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2496 - val_loss: 0.5735\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8800 - val_loss: 0.7560\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6097 - val_loss: 0.5871\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5224 - val_loss: 0.5548\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5922 - val_loss: 0.7250\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3730 - val_loss: 2.8570\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1820 - val_loss: 0.9670\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7294 - val_loss: 0.9537\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6817 - val_loss: 0.5650\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6348 - val_loss: 0.5675\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6706 - val_loss: 1.2943\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8994 - val_loss: 0.7268\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8866 - val_loss: 0.8805\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7723 - val_loss: 0.6239\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5819 - val_loss: 0.7009\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8276 - val_loss: 1.3520\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7518 - val_loss: 0.6595\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5078 - val_loss: 0.5751\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5201 - val_loss: 0.7618\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5544 - val_loss: 0.5826\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9154 - val_loss: 2.0827\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8474 - val_loss: 0.7226\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5065 - val_loss: 0.5455\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5687 - val_loss: 0.8686\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5458 - val_loss: 0.6141\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9359 - val_loss: 0.6761\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9768 - val_loss: 0.5520\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6804 - val_loss: 2.5601\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0181 - val_loss: 0.7701\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5818 - val_loss: 0.5510\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4857 - val_loss: 0.5431\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4984 - val_loss: 0.5968\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5614 - val_loss: 1.0626\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7446 - val_loss: 1.2581\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9299 - val_loss: 0.8468\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 0.6828\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5851 - val_loss: 0.5538\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5124 - val_loss: 0.5398\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5339 - val_loss: 0.5795\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4410 - val_loss: 0.5281\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4949 - val_loss: 0.5311\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6731 - val_loss: 2.1227\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8954 - val_loss: 1.1011\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.9777\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7194 - val_loss: 0.5717\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5935 - val_loss: 0.5841\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4689 - val_loss: 0.8710\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7127 - val_loss: 0.5728\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6435 - val_loss: 2.0520\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1240 - val_loss: 0.6576\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5335 - val_loss: 0.7352\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6110 - val_loss: 0.5649\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0016 - val_loss: 0.5433\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5181 - val_loss: 0.7026\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4938 - val_loss: 0.5438\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7085 - val_loss: 0.7760\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7226 - val_loss: 1.1105\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7519 - val_loss: 0.5140\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7256 - val_loss: 0.7337\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8824 - val_loss: 0.5077\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6449 - val_loss: 0.6333\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.8046\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1181 - val_loss: 1.7712\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9524 - val_loss: 2.0311\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2968 - val_loss: 0.5814\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9077 - val_loss: 0.5283\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6248 - val_loss: 0.5662\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5039 - val_loss: 0.5127\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5725 - val_loss: 0.5124\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9419 - val_loss: 0.5683\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4918 - val_loss: 0.5596\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4624 - val_loss: 0.5564\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5652 - val_loss: 0.6079\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6262 - val_loss: 0.6074\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6458 - val_loss: 0.6537\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1364 - val_loss: 0.9659\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6545 - val_loss: 0.5130\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - val_loss: 0.5086\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5763 - val_loss: 0.6362\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4691 - val_loss: 0.5328\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4697 - val_loss: 0.8638\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5699 - val_loss: 0.5163\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7603 - val_loss: 1.8442\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7130 - val_loss: 0.5411\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5962 - val_loss: 0.6201\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9418 - val_loss: 1.1836\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6629 - val_loss: 0.8216\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6013 - val_loss: 0.6031\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7969 - val_loss: 0.5264\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0732 - val_loss: 2.1534\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8311 - val_loss: 0.9114\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9442 - val_loss: 0.5120\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7864 - val_loss: 1.3028\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8958 - val_loss: 0.8683\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7332 - val_loss: 0.5709\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6272 - val_loss: 1.3985\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8097 - val_loss: 1.4916\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7703 - val_loss: 0.7074\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7784 - val_loss: 0.8152\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5607 - val_loss: 1.0494\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3139 - val_loss: 1.4881\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5417 - val_loss: 0.9355\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1507 - val_loss: 0.6369\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6517 - val_loss: 0.8075\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4733 - val_loss: 0.5740\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6114 - val_loss: 1.1462\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6346 - val_loss: 0.5096\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4697 - val_loss: 1.2191\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7707 - val_loss: 0.4960\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7811 - val_loss: 0.5836\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5165 - val_loss: 0.5630\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7000 - val_loss: 1.3699\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8216 - val_loss: 0.6781\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7401 - val_loss: 1.9602\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8839 - val_loss: 0.5171\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7291 - val_loss: 0.8264\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5278 - val_loss: 0.4996\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - val_loss: 0.5505\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5618 - val_loss: 0.5282\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8798 - val_loss: 1.1807\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9966 - val_loss: 1.4316\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9903 - val_loss: 1.1133\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4797 - val_loss: 0.5003\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5504 - val_loss: 0.6149\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4193 - val_loss: 0.5099\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6119 - val_loss: 0.5441\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5470 - val_loss: 0.5921\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5024 - val_loss: 0.6932\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4439 - val_loss: 0.6494\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4202 - val_loss: 0.5475\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4499 - val_loss: 0.5014\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4489 - val_loss: 0.7080\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7869 - val_loss: 0.5152\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5257 - val_loss: 0.5504\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4612 - val_loss: 0.7292\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5030 - val_loss: 0.5233\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.5119\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5555 - val_loss: 1.2275\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5156 - val_loss: 1.2970\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1039 - val_loss: 0.5179\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1832 - val_loss: 1.1719\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6700 - val_loss: 0.6294\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8815 - val_loss: 0.5031\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5856 - val_loss: 0.7500\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5717 - val_loss: 0.8253\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5659 - val_loss: 0.9172\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5572 - val_loss: 0.5889\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6125 - val_loss: 0.9582\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5796 - val_loss: 0.5014\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7863 - val_loss: 0.5187\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6176 - val_loss: 0.6069\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4610 - val_loss: 0.6733\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5094 - val_loss: 0.6387\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8238 - val_loss: 0.5783\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6963 - val_loss: 0.7402\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4367 - val_loss: 0.5702\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4710 - val_loss: 1.1587\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6698 - val_loss: 0.7016\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6025 - val_loss: 0.6868\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5034 - val_loss: 0.5151\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8271 - val_loss: 1.2745\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5608 - val_loss: 3.0647\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4653 - val_loss: 0.5368\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5386 - val_loss: 0.7927\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5533 - val_loss: 0.5812\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5222 - val_loss: 1.1715\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.6586\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5322 - val_loss: 0.5046\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 1.2063\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6064 - val_loss: 0.4994\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5603 - val_loss: 0.4965\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5187 - val_loss: 0.5593\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4968 - val_loss: 0.5228\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4988 - val_loss: 0.6510\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5629 - val_loss: 0.5030\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4526 - val_loss: 0.5082\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5034 - val_loss: 0.8747\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6896 - val_loss: 0.5150\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6779 - val_loss: 0.6260\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5262 - val_loss: 0.5408\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4426 - val_loss: 0.5380\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4631 - val_loss: 0.8831\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7699 - val_loss: 1.1124\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1336 - val_loss: 1.8556\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6744 - val_loss: 0.5124\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5809 - val_loss: 0.5951\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6342 - val_loss: 0.7539\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4833 - val_loss: 0.5487\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4398 - val_loss: 0.7071\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5197 - val_loss: 0.4841\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4167 - val_loss: 0.5124\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3728 - val_loss: 0.6965\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5736 - val_loss: 0.4895\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4491 - val_loss: 0.6603\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6296 - val_loss: 0.5087\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7569 - val_loss: 0.8751\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7926 - val_loss: 0.5331\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0978 - val_loss: 1.2757\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5897 - val_loss: 0.4958\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4001 - val_loss: 0.4992\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6116 - val_loss: 0.8687\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8363 - val_loss: 0.9844\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5613 - val_loss: 0.5278\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6702 - val_loss: 0.5341\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7016 - val_loss: 1.7312\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8037 - val_loss: 0.7638\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6416 - val_loss: 0.5598\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - val_loss: 0.4799\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.9237\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9134 - val_loss: 0.5537\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4763 - val_loss: 0.8889\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5470 - val_loss: 0.5562\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6312 - val_loss: 1.9790\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0998 - val_loss: 1.6717\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8073 - val_loss: 1.3042\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6980 - val_loss: 0.5986\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6414 - val_loss: 0.5437\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2701 - val_loss: 0.6181\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9969 - val_loss: 0.5143\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0111 - val_loss: 0.8276\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0075 - val_loss: 0.8407\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8584 - val_loss: 0.4898\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4317 - val_loss: 0.6655\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6380 - val_loss: 0.6069\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6390 - val_loss: 0.4759\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4587 - val_loss: 0.5069\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3878 - val_loss: 0.4885\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3912 - val_loss: 0.7778\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6911 - val_loss: 1.1042\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8065 - val_loss: 0.4863\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4751 - val_loss: 0.5158\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4205 - val_loss: 0.4761\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4240 - val_loss: 0.4700\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4629 - val_loss: 0.7283\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6719 - val_loss: 0.9229\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5948 - val_loss: 0.4881\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4858 - val_loss: 1.1297\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5691 - val_loss: 0.4777\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4903 - val_loss: 0.6002\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6957 - val_loss: 0.5833\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5498 - val_loss: 0.4742\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4464 - val_loss: 0.5232\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6257 - val_loss: 0.7781\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9531 - val_loss: 0.6077\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6174 - val_loss: 0.4905\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4223 - val_loss: 0.7667\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6833 - val_loss: 0.9483\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7674 - val_loss: 0.6772\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3997 - val_loss: 0.5228\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4607 - val_loss: 0.8425\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9309 - val_loss: 0.4858\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0129 - val_loss: 0.6959\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5697 - val_loss: 0.6035\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1661 - val_loss: 0.5986\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1492 - val_loss: 1.0122\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9458 - val_loss: 1.8110\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.8643 - val_loss: 0.8284\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5870 - val_loss: 0.8275\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4684 - val_loss: 0.4802\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4548 - val_loss: 0.5280\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4712 - val_loss: 0.6574\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 2.0889\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9085 - val_loss: 0.5162\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6456 - val_loss: 0.4859\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 271.1942 - val_loss: 68.6724\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.6257 - val_loss: 20.7260\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.6435 - val_loss: 4.7846\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3.8296 - val_loss: 2.5079\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.2052 - val_loss: 1.1220\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6811 - val_loss: 1.0648\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6529 - val_loss: 1.1560\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6500 - val_loss: 1.0893\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6630 - val_loss: 1.0621\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6496 - val_loss: 1.0746\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6738 - val_loss: 1.5248\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7919 - val_loss: 1.1486\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6823 - val_loss: 1.2436\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7055 - val_loss: 1.2199\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7880 - val_loss: 1.2754\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.7420 - val_loss: 1.1600\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7263 - val_loss: 1.1977\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5822 - val_loss: 1.0522\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6729 - val_loss: 1.0513\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7554 - val_loss: 1.0775\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7926 - val_loss: 1.1754\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7327 - val_loss: 1.3900\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6180 - val_loss: 1.1163\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.7187 - val_loss: 1.0398\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5317 - val_loss: 1.4578\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7518 - val_loss: 1.1139\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5623 - val_loss: 1.0255\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7399 - val_loss: 1.0231\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7566 - val_loss: 1.7779\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7942 - val_loss: 1.0589\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7610 - val_loss: 1.0394\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7804 - val_loss: 1.6734\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7018 - val_loss: 1.0080\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5640 - val_loss: 1.4667\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7266 - val_loss: 1.5454\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5762 - val_loss: 1.1425\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4649 - val_loss: 0.9984\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6269 - val_loss: 1.3424\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5882 - val_loss: 0.9968\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4959 - val_loss: 1.0854\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4411 - val_loss: 0.9905\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6852 - val_loss: 1.5337\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.3729 - val_loss: 1.1271\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.2990 - val_loss: 1.0376\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9105 - val_loss: 2.2547\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8940 - val_loss: 1.3074\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8601 - val_loss: 1.2006\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4991 - val_loss: 0.9757\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7822 - val_loss: 0.9774\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.6360 - val_loss: 1.0861\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7953 - val_loss: 1.3919\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0997 - val_loss: 1.0300\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.9584 - val_loss: 1.4544\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.0023 - val_loss: 2.0210\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7277 - val_loss: 1.2530\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6784 - val_loss: 1.8885\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7603 - val_loss: 0.9601\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3775 - val_loss: 0.9896\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4350 - val_loss: 0.9582\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5798 - val_loss: 0.9600\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4522 - val_loss: 1.1045\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5395 - val_loss: 0.9719\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4960 - val_loss: 1.2805\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5612 - val_loss: 1.2108\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7349 - val_loss: 1.2099\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8117 - val_loss: 2.8712\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7778 - val_loss: 1.7670\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.5375 - val_loss: 0.9439\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5552 - val_loss: 1.5053\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.7302 - val_loss: 0.9573\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8429 - val_loss: 1.1764\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4336 - val_loss: 1.5939\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4380 - val_loss: 0.9781\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3812 - val_loss: 1.0820\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6583 - val_loss: 1.5050\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6397 - val_loss: 0.9310\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3811 - val_loss: 1.6008\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8546 - val_loss: 1.6741\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6601 - val_loss: 1.1701\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3792 - val_loss: 0.9248\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5792 - val_loss: 0.9245\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3404 - val_loss: 1.3241\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3802 - val_loss: 1.1906\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4093 - val_loss: 1.7284\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5579 - val_loss: 1.5459\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4799 - val_loss: 1.1001\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.8293 - val_loss: 1.3554\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5761 - val_loss: 1.2455\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4266 - val_loss: 1.0188\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3795 - val_loss: 0.9095\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2709 - val_loss: 1.0558\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2454 - val_loss: 1.2027\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2483 - val_loss: 0.9051\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3076 - val_loss: 0.9249\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3532 - val_loss: 0.9400\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5160 - val_loss: 1.2470\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3293 - val_loss: 2.0057\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9713 - val_loss: 1.5081\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9616 - val_loss: 0.9177\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9646 - val_loss: 1.1159\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9354 - val_loss: 1.1598\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6153 - val_loss: 1.2329\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4731 - val_loss: 1.1059\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5051 - val_loss: 0.8736\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4554 - val_loss: 1.2940\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3649 - val_loss: 0.9074\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.8308 - val_loss: 2.8552\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0900 - val_loss: 1.0601\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.1940 - val_loss: 0.8612\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.3273 - val_loss: 2.9202\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9231 - val_loss: 1.5145\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3110 - val_loss: 1.3309\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0378 - val_loss: 1.6326\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5958 - val_loss: 1.0389\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4437 - val_loss: 1.0719\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.7890 - val_loss: 1.2702\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2251 - val_loss: 2.1105\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3751 - val_loss: 1.1173\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1712 - val_loss: 0.8988\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3004 - val_loss: 0.8592\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2553 - val_loss: 0.9268\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1381 - val_loss: 0.8397\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3011 - val_loss: 0.9029\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2105 - val_loss: 0.8860\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3643 - val_loss: 1.1718\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2544 - val_loss: 0.9979\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1704 - val_loss: 1.0239\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1933 - val_loss: 0.8709\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2396 - val_loss: 0.9551\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1416 - val_loss: 0.9292\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1828 - val_loss: 0.8152\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1444 - val_loss: 1.1051\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3791 - val_loss: 2.8989\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9276 - val_loss: 1.5088\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1565 - val_loss: 0.8495\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1765 - val_loss: 0.9753\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1506 - val_loss: 0.8589\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4327 - val_loss: 0.9342\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1402 - val_loss: 0.8836\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4996 - val_loss: 1.9878\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7301 - val_loss: 0.8136\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1323 - val_loss: 0.8904\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4528 - val_loss: 1.1107\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2335 - val_loss: 1.1384\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1282 - val_loss: 0.8142\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0517 - val_loss: 0.7783\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0443 - val_loss: 2.2527\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4584 - val_loss: 1.5011\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4744 - val_loss: 0.9278\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1549 - val_loss: 0.8620\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1899 - val_loss: 0.9256\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3001 - val_loss: 1.1624\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1010 - val_loss: 0.8578\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0214 - val_loss: 0.8935\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2635 - val_loss: 0.8526\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3660 - val_loss: 0.9203\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2020 - val_loss: 1.1040\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1170 - val_loss: 0.7952\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4135 - val_loss: 1.3813\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1135 - val_loss: 0.9403\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.3272 - val_loss: 1.7698\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5056 - val_loss: 1.1473\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1298 - val_loss: 1.1819\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5177 - val_loss: 1.8677\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7906 - val_loss: 1.0745\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0794 - val_loss: 0.8300\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9781 - val_loss: 0.9728\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0082 - val_loss: 1.0922\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6311 - val_loss: 0.8768\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2344 - val_loss: 1.5203\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6172 - val_loss: 0.9607\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1641 - val_loss: 0.7872\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2665 - val_loss: 0.8791\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0539 - val_loss: 0.7247\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0140 - val_loss: 1.2461\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0292 - val_loss: 0.7515\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2357 - val_loss: 1.3094\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9254 - val_loss: 0.7214\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2187 - val_loss: 2.0577\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1527 - val_loss: 0.7700\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9917 - val_loss: 1.2529\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6856 - val_loss: 0.9881\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.7126 - val_loss: 1.8723\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3103 - val_loss: 2.4260\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6823 - val_loss: 0.7248\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9659 - val_loss: 0.7281\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1117 - val_loss: 1.6932\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0800 - val_loss: 0.7153\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9416 - val_loss: 0.8923\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1087 - val_loss: 1.1541\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2078 - val_loss: 1.6320\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2494 - val_loss: 1.0745\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2204 - val_loss: 1.5812\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4880 - val_loss: 0.9476\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0672 - val_loss: 1.1232\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0614 - val_loss: 0.7147\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2396 - val_loss: 1.1900\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0165 - val_loss: 0.7769\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9037 - val_loss: 0.9562\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2023 - val_loss: 3.0112\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.4599 - val_loss: 0.9396\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5284 - val_loss: 0.7617\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2868 - val_loss: 1.4207\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5547 - val_loss: 1.4567\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9854 - val_loss: 0.7539\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9034 - val_loss: 0.7150\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8072 - val_loss: 0.7597\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0250 - val_loss: 0.7259\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0140 - val_loss: 0.9203\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9437 - val_loss: 0.9524\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5153 - val_loss: 0.7360\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.0788 - val_loss: 1.2510\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.0907 - val_loss: 2.5850\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0559 - val_loss: 0.7401\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8291 - val_loss: 1.0946\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7510 - val_loss: 1.7142\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5366 - val_loss: 0.9385\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6424 - val_loss: 0.7031\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1852 - val_loss: 1.1148\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0657 - val_loss: 1.3714\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1879 - val_loss: 1.7641\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5830 - val_loss: 0.8177\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8207 - val_loss: 0.7783\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8911 - val_loss: 0.8004\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8201 - val_loss: 0.7047\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7473 - val_loss: 0.9943\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8170 - val_loss: 1.0687\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0225 - val_loss: 0.8435\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0973 - val_loss: 1.0175\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2896 - val_loss: 1.2918\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9246 - val_loss: 0.7103\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8742 - val_loss: 0.7629\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9861 - val_loss: 0.9717\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3151 - val_loss: 0.9537\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9339 - val_loss: 0.8078\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7919 - val_loss: 0.9486\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9100 - val_loss: 0.7098\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7629 - val_loss: 0.7125\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7676 - val_loss: 0.7029\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7914 - val_loss: 1.0023\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0306 - val_loss: 1.4121\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 2.4936 - val_loss: 6.0469\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0959 - val_loss: 0.7446\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6833 - val_loss: 0.8590\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7618 - val_loss: 1.1146\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9632 - val_loss: 0.7053\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8041 - val_loss: 1.4700\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9930 - val_loss: 0.8146\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8830 - val_loss: 1.7746\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1251 - val_loss: 0.7245\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8370 - val_loss: 0.7659\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9236 - val_loss: 1.4438\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8625 - val_loss: 1.0468\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8143 - val_loss: 0.7215\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9076 - val_loss: 1.6702\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0601 - val_loss: 0.8819\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7806 - val_loss: 0.7112\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8583 - val_loss: 2.0763\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1587 - val_loss: 0.9262\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8777 - val_loss: 0.8132\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9635 - val_loss: 0.9393\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7682 - val_loss: 0.7412\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0209 - val_loss: 1.8613\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0486 - val_loss: 0.9533\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9189 - val_loss: 0.9389\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1056 - val_loss: 1.3847\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9424 - val_loss: 0.7631\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2250 - val_loss: 3.7284\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6602 - val_loss: 1.2968\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2937 - val_loss: 0.7563\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0305 - val_loss: 0.8715\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8373 - val_loss: 1.2053\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0710 - val_loss: 0.8383\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9731 - val_loss: 0.8950\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9947 - val_loss: 0.8567\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8303 - val_loss: 0.7379\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7305 - val_loss: 0.7034\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8436 - val_loss: 0.6915\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3535 - val_loss: 2.0408\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0031 - val_loss: 0.7526\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9699 - val_loss: 0.8477\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7369 - val_loss: 0.6992\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7412 - val_loss: 1.5904\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1017 - val_loss: 0.8162\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8059 - val_loss: 1.8182\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9760 - val_loss: 0.7031\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8678 - val_loss: 0.9835\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2340 - val_loss: 1.0939\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8740 - val_loss: 0.6980\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7316 - val_loss: 0.8267\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9647 - val_loss: 0.9890\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8039 - val_loss: 0.7949\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8229 - val_loss: 0.7814\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6886 - val_loss: 0.6944\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7289 - val_loss: 0.9379\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0094 - val_loss: 1.0588\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8306 - val_loss: 0.7694\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7245 - val_loss: 1.1241\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8757 - val_loss: 0.7674\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8755 - val_loss: 0.7496\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6939 - val_loss: 0.6888\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7396 - val_loss: 0.6843\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8570 - val_loss: 0.9123\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2483 - val_loss: 2.0585\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4594 - val_loss: 1.3424\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0003 - val_loss: 1.8633\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5147 - val_loss: 1.0728\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8741 - val_loss: 0.8303\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0591 - val_loss: 0.7043\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3731 - val_loss: 1.7855\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4187 - val_loss: 1.3675\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7830 - val_loss: 0.7367\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6651 - val_loss: 0.7064\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6536 - val_loss: 0.6978\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8772 - val_loss: 1.0342\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8889 - val_loss: 0.6787\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9130 - val_loss: 1.9467\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0851 - val_loss: 0.8249\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0741 - val_loss: 0.8667\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7233 - val_loss: 0.7679\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7391 - val_loss: 0.6870\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8776 - val_loss: 0.7961\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9095 - val_loss: 1.0149\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7816 - val_loss: 0.7551\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1142 - val_loss: 2.0282\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8479 - val_loss: 0.6852\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9694 - val_loss: 0.7052\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7267 - val_loss: 0.7070\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6333 - val_loss: 1.1007\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0622 - val_loss: 1.0525\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 0.7364\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6542 - val_loss: 0.8341\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8566 - val_loss: 0.9671\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1604 - val_loss: 0.6966\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6443 - val_loss: 1.0315\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7924 - val_loss: 2.4594\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9298 - val_loss: 3.2175\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6153 - val_loss: 3.1183\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9117 - val_loss: 0.7274\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0564 - val_loss: 1.4848\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7650 - val_loss: 0.7022\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7689 - val_loss: 0.9017\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7299 - val_loss: 0.6749\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7180 - val_loss: 1.1059\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9153 - val_loss: 0.6851\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6871 - val_loss: 0.7087\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6164 - val_loss: 0.7274\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7283 - val_loss: 0.6944\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7651 - val_loss: 1.4277\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1894 - val_loss: 0.6763\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8034 - val_loss: 1.8977\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2349 - val_loss: 0.7370\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7716 - val_loss: 0.6642\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6123 - val_loss: 0.6760\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6980 - val_loss: 0.6616\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.3810 - val_loss: 0.8987\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6625\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7450 - val_loss: 0.7263\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8673 - val_loss: 0.7988\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9318 - val_loss: 0.6753\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6561\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6905 - val_loss: 0.7468\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8553 - val_loss: 0.8221\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8786 - val_loss: 0.9262\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8224 - val_loss: 0.6816\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9463 - val_loss: 1.5846\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9687 - val_loss: 0.9653\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5945 - val_loss: 0.7268\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9335 - val_loss: 0.6525\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8920 - val_loss: 0.9409\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8049 - val_loss: 0.6522\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7320 - val_loss: 1.1523\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6391 - val_loss: 0.8405\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1757 - val_loss: 2.5414\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1963 - val_loss: 1.2721\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.4871 - val_loss: 1.4802\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0739 - val_loss: 0.7435\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2987 - val_loss: 1.2988\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3740 - val_loss: 1.1729\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7357 - val_loss: 1.6165\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8941 - val_loss: 0.8660\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6768 - val_loss: 1.0297\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6794 - val_loss: 1.0895\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1523 - val_loss: 0.8791\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9907 - val_loss: 1.1879\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9453 - val_loss: 0.6344\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9333 - val_loss: 1.0400\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9312 - val_loss: 0.9251\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6322 - val_loss: 0.7610\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7047 - val_loss: 1.0361\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7274 - val_loss: 0.6553\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 1.1003\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7581 - val_loss: 0.6821\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7486 - val_loss: 0.6576\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5782 - val_loss: 0.6613\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6329 - val_loss: 0.7319\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6441 - val_loss: 0.6548\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8851 - val_loss: 0.8010\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8707 - val_loss: 1.5893\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1705 - val_loss: 1.2234\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1513 - val_loss: 0.7163\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2387 - val_loss: 4.5815\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1972 - val_loss: 0.8468\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4879 - val_loss: 1.6810\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9975 - val_loss: 0.7017\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5752 - val_loss: 0.6994\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7362 - val_loss: 1.0308\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.6247\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5579 - val_loss: 0.6365\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7308 - val_loss: 0.6347\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6296 - val_loss: 1.4380\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9251 - val_loss: 0.7374\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8166 - val_loss: 0.6632\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6186 - val_loss: 1.0017\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7667 - val_loss: 0.7800\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5576 - val_loss: 0.6129\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7984 - val_loss: 2.2510\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9717 - val_loss: 1.0462\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9593 - val_loss: 0.6104\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5592 - val_loss: 0.8543\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6424 - val_loss: 0.6422\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5924 - val_loss: 0.7520\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5989 - val_loss: 0.6219\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5270 - val_loss: 1.1204\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8495 - val_loss: 0.7826\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9246 - val_loss: 1.1054\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7901 - val_loss: 0.6219\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5665 - val_loss: 0.6726\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.6212\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5070 - val_loss: 0.6919\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6032\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0215 - val_loss: 0.8600\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9596 - val_loss: 0.6306\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5869 - val_loss: 0.6017\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5319 - val_loss: 0.6131\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5711 - val_loss: 0.6867\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6986 - val_loss: 0.8235\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8668 - val_loss: 1.4339\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8916 - val_loss: 0.7825\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6503 - val_loss: 0.5946\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5406 - val_loss: 0.9619\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5516 - val_loss: 0.6171\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5310 - val_loss: 0.6085\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6601 - val_loss: 0.5889\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5627 - val_loss: 0.6042\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7583 - val_loss: 0.6849\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7254 - val_loss: 0.6535\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5501 - val_loss: 0.5847\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.8547\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9259 - val_loss: 1.2707\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1152 - val_loss: 0.9957\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7525 - val_loss: 0.5982\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.6420\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0301 - val_loss: 1.1186\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7758 - val_loss: 0.8788\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9822 - val_loss: 3.2275\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.9334 - val_loss: 0.9293\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8412 - val_loss: 1.0778\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9498 - val_loss: 0.5905\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8096 - val_loss: 1.3765\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6068 - val_loss: 0.5837\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5204 - val_loss: 0.7461\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5787 - val_loss: 1.0567\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6903 - val_loss: 0.5875\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6261 - val_loss: 0.6111\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8929 - val_loss: 1.1165\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8593 - val_loss: 0.5692\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5917 - val_loss: 0.5983\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6462 - val_loss: 0.6283\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5002 - val_loss: 0.5740\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5378 - val_loss: 0.5895\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4928 - val_loss: 0.5618\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6319 - val_loss: 1.1507\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6216 - val_loss: 0.5686\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5994 - val_loss: 0.5698\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5350 - val_loss: 0.5948\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4979 - val_loss: 0.5606\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5614 - val_loss: 0.9767\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8707 - val_loss: 1.5353\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.0574 - val_loss: 1.1394\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8368 - val_loss: 1.2207\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9007 - val_loss: 0.7444\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8243 - val_loss: 0.5559\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6094 - val_loss: 0.6202\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.7145\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 1.1906\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8366 - val_loss: 1.3181\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9221 - val_loss: 0.7269\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7482 - val_loss: 1.3949\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6043 - val_loss: 0.6343\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5394 - val_loss: 0.7803\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8042 - val_loss: 1.3217\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7537 - val_loss: 0.5712\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6515 - val_loss: 0.5329\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5078 - val_loss: 0.6860\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5404 - val_loss: 0.7218\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5756 - val_loss: 0.6265\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 1.3382\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6708 - val_loss: 0.5941\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.7707\n",
            "Epoch 1/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 430.9630 - val_loss: 75.8318\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 40.3563 - val_loss: 8.6577\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 11.2332 - val_loss: 3.1866\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5.5520 - val_loss: 4.5545\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.5000 - val_loss: 2.0592\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2.0548 - val_loss: 1.6732\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8675 - val_loss: 1.6315\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8200 - val_loss: 1.6242\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8097 - val_loss: 1.5900\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7658 - val_loss: 1.5844\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8332 - val_loss: 1.6157\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.8327 - val_loss: 1.5284\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7610 - val_loss: 1.5212\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7094 - val_loss: 1.5058\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7260 - val_loss: 1.4826\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7101 - val_loss: 1.5479\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7309 - val_loss: 1.4418\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.6825 - val_loss: 1.4517\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7116 - val_loss: 1.4054\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6596 - val_loss: 1.3903\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6550 - val_loss: 1.3864\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6545 - val_loss: 1.4177\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8350 - val_loss: 1.3399\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6299 - val_loss: 1.4730\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6152 - val_loss: 1.8696\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.8162 - val_loss: 2.0136\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.7113 - val_loss: 1.3170\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6119 - val_loss: 1.2574\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4941 - val_loss: 1.4856\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.6025 - val_loss: 1.2945\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6352 - val_loss: 1.2494\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5006 - val_loss: 1.3276\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4661 - val_loss: 1.1691\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4643 - val_loss: 1.1567\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5107 - val_loss: 1.2327\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7157 - val_loss: 1.2587\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.5705 - val_loss: 1.1866\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5375 - val_loss: 1.1228\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3722 - val_loss: 1.2432\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4224 - val_loss: 1.0681\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3613 - val_loss: 1.1814\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5766 - val_loss: 1.2252\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3775 - val_loss: 1.1695\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3440 - val_loss: 0.9968\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3001 - val_loss: 1.0371\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3174 - val_loss: 1.0465\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3335 - val_loss: 0.9597\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2563 - val_loss: 1.0609\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2513 - val_loss: 0.9234\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2484 - val_loss: 0.9384\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4250 - val_loss: 1.0212\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2769 - val_loss: 0.9731\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2508 - val_loss: 0.8899\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2237 - val_loss: 1.2028\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2812 - val_loss: 0.8696\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1663 - val_loss: 0.8577\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2010 - val_loss: 1.1027\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4490 - val_loss: 1.2727\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4271 - val_loss: 1.3884\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7093 - val_loss: 1.8324\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5738 - val_loss: 2.5502\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.7012 - val_loss: 1.0478\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2646 - val_loss: 0.8578\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2117 - val_loss: 0.8742\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1228 - val_loss: 0.8336\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1854 - val_loss: 0.7940\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2669 - val_loss: 0.7980\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1196 - val_loss: 0.9946\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1194 - val_loss: 0.8314\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1528 - val_loss: 0.9446\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1856 - val_loss: 0.8429\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0427 - val_loss: 0.8420\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9958 - val_loss: 1.0196\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0130 - val_loss: 0.7372\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0402 - val_loss: 0.7293\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9761 - val_loss: 0.7208\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9727 - val_loss: 1.3331\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0882 - val_loss: 0.9740\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0633 - val_loss: 0.7045\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9322 - val_loss: 0.8361\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0027 - val_loss: 0.7150\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9211 - val_loss: 0.6926\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8791 - val_loss: 0.8643\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9200 - val_loss: 0.7954\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0284 - val_loss: 0.7096\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0163 - val_loss: 0.8720\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0757 - val_loss: 0.7209\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.9553 - val_loss: 0.6702\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8716 - val_loss: 0.6513\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8595 - val_loss: 0.6443\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8039 - val_loss: 1.0120\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7954 - val_loss: 0.6600\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7813 - val_loss: 0.6147\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7617 - val_loss: 0.6118\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7986 - val_loss: 0.6730\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7835 - val_loss: 0.6258\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7781 - val_loss: 0.7068\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8981 - val_loss: 0.7337\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9810 - val_loss: 0.7022\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0621 - val_loss: 0.6535\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8030 - val_loss: 0.6357\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7630 - val_loss: 0.6809\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7746 - val_loss: 0.5898\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.8987 - val_loss: 0.7581\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7359 - val_loss: 0.5778\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6937 - val_loss: 0.6923\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9538 - val_loss: 2.1292\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3443 - val_loss: 1.1137\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2429 - val_loss: 0.6151\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6941 - val_loss: 0.5860\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7180 - val_loss: 1.9070\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2320 - val_loss: 1.5454\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.6772 - val_loss: 0.6094\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9478 - val_loss: 0.6176\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8631 - val_loss: 0.6045\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6983 - val_loss: 0.8730\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9781 - val_loss: 1.2742\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7714 - val_loss: 0.5728\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7599 - val_loss: 0.6716\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7295 - val_loss: 0.5739\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6482 - val_loss: 0.5589\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 0.8057\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7946 - val_loss: 0.5434\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6488 - val_loss: 0.5497\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7928 - val_loss: 0.5476\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6151 - val_loss: 0.6150\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6057 - val_loss: 0.6869\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6977 - val_loss: 0.6907\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.5519\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 0.9142\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7736 - val_loss: 0.5560\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6562 - val_loss: 0.6116\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 0.9576\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0231 - val_loss: 0.6198\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8897 - val_loss: 0.8237\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7767 - val_loss: 0.7003\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9019 - val_loss: 0.6529\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.1144 - val_loss: 1.4631\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8769 - val_loss: 0.5157\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0639 - val_loss: 0.5424\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5731 - val_loss: 0.5135\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5506 - val_loss: 0.9266\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6848 - val_loss: 0.5543\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5968 - val_loss: 0.6909\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.5001\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5827 - val_loss: 0.5785\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6449 - val_loss: 0.9036\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.7925 - val_loss: 0.9632\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6777 - val_loss: 0.5188\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6013 - val_loss: 0.6734\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6331 - val_loss: 0.6836\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.5242\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5300 - val_loss: 0.5131\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5603 - val_loss: 0.5901\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5225 - val_loss: 0.5756\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5436 - val_loss: 0.5844\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5385 - val_loss: 0.5623\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5803 - val_loss: 0.5999\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.7298\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6031 - val_loss: 0.8293\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6422 - val_loss: 1.3808\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9151 - val_loss: 0.4941\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5381 - val_loss: 0.8433\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7170 - val_loss: 0.5771\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6323 - val_loss: 0.5742\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5212 - val_loss: 0.5012\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6032 - val_loss: 0.8025\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.8902\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8243 - val_loss: 0.8005\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7542 - val_loss: 0.4952\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6904 - val_loss: 0.5333\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5913 - val_loss: 0.6674\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6361 - val_loss: 0.4739\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5012 - val_loss: 0.4804\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4816 - val_loss: 0.6533\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5960 - val_loss: 0.5298\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6359 - val_loss: 0.9504\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5576 - val_loss: 0.4811\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5603 - val_loss: 0.6380\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6202 - val_loss: 0.7248\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6345 - val_loss: 0.5044\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7670 - val_loss: 0.5762\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5100 - val_loss: 0.4710\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5238 - val_loss: 1.0165\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6792 - val_loss: 0.6955\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5857 - val_loss: 0.6875\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5602 - val_loss: 0.5159\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5485 - val_loss: 0.5287\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6251 - val_loss: 0.4590\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6280 - val_loss: 0.5236\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2519 - val_loss: 1.0970\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9416 - val_loss: 0.6684\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6101 - val_loss: 0.9843\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6923 - val_loss: 0.4478\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4846 - val_loss: 1.0450\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8497 - val_loss: 0.7440\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5235 - val_loss: 0.4671\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4752 - val_loss: 0.4576\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5274 - val_loss: 0.4768\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4990 - val_loss: 0.9251\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8301 - val_loss: 0.9096\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9004 - val_loss: 0.7921\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8509 - val_loss: 0.5459\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6693 - val_loss: 0.5753\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5317 - val_loss: 0.4749\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4777 - val_loss: 0.4643\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4791 - val_loss: 0.4677\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5398 - val_loss: 0.4753\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4434 - val_loss: 0.5553\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4496 - val_loss: 0.5259\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7889 - val_loss: 0.4365\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9989 - val_loss: 1.1712\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1165 - val_loss: 0.7312\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0183 - val_loss: 0.5514\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7523 - val_loss: 0.7796\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5697 - val_loss: 0.4774\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4712 - val_loss: 0.7475\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9518 - val_loss: 1.1972\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8662 - val_loss: 0.5345\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6126 - val_loss: 0.4985\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6693 - val_loss: 0.4310\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6703 - val_loss: 0.6239\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7369 - val_loss: 0.4420\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6392 - val_loss: 0.7560\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5773 - val_loss: 0.4482\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5421 - val_loss: 1.0736\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6127 - val_loss: 0.4827\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5107 - val_loss: 0.4437\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6349 - val_loss: 0.5380\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5416 - val_loss: 0.4673\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6225 - val_loss: 0.8846\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7489 - val_loss: 0.9591\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8274 - val_loss: 0.4701\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5792 - val_loss: 0.6164\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4611 - val_loss: 0.7833\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4969 - val_loss: 0.4698\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4392 - val_loss: 0.4551\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 0.4318\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4954 - val_loss: 0.4760\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4717 - val_loss: 0.4297\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4259 - val_loss: 0.9175\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0549 - val_loss: 0.5135\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5735 - val_loss: 0.5061\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4374 - val_loss: 0.4518\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4460 - val_loss: 0.5003\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4912 - val_loss: 0.5376\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5811 - val_loss: 0.4397\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4327 - val_loss: 0.4576\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4862 - val_loss: 1.1105\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8909 - val_loss: 0.8424\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5902 - val_loss: 0.6991\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6170 - val_loss: 0.5491\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5483 - val_loss: 0.4375\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4344 - val_loss: 0.4426\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4345 - val_loss: 0.6909\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5054 - val_loss: 0.4406\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5207 - val_loss: 0.5832\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7146 - val_loss: 1.0926\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9513 - val_loss: 1.5230\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7421 - val_loss: 0.9713\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5495 - val_loss: 0.4835\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6313 - val_loss: 0.4406\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4089 - val_loss: 0.6077\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4670 - val_loss: 0.9235\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6869 - val_loss: 1.1138\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6778 - val_loss: 0.4743\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4950 - val_loss: 0.4344\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4597 - val_loss: 0.6927\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.4804\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4899 - val_loss: 0.8737\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4781 - val_loss: 0.4537\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4154 - val_loss: 0.5389\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4975 - val_loss: 0.4262\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - val_loss: 0.5103\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7072 - val_loss: 0.4512\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5179 - val_loss: 0.4833\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4048 - val_loss: 0.4244\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4851 - val_loss: 0.4364\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7581 - val_loss: 0.7398\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5640 - val_loss: 0.9427\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6710\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6242 - val_loss: 0.4433\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6727 - val_loss: 1.2552\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6576 - val_loss: 0.6744\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5484 - val_loss: 0.5155\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5185 - val_loss: 0.5674\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4165 - val_loss: 0.4615\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4055 - val_loss: 0.4681\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - val_loss: 0.5316\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4466 - val_loss: 0.4809\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4251 - val_loss: 0.6790\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4231 - val_loss: 0.5188\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3943 - val_loss: 0.4257\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - val_loss: 0.4899\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4820 - val_loss: 0.6047\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5566 - val_loss: 0.4208\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4491 - val_loss: 0.4542\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4386 - val_loss: 0.7468\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5558 - val_loss: 0.4222\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4091 - val_loss: 0.5675\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5184 - val_loss: 0.6386\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4927 - val_loss: 0.4226\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4285 - val_loss: 0.5663\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4376 - val_loss: 0.4265\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4397 - val_loss: 0.6092\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5785 - val_loss: 1.1955\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.9141 - val_loss: 0.5183\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.5987\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4734 - val_loss: 0.6084\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7336 - val_loss: 0.9486\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7393 - val_loss: 0.5052\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3950 - val_loss: 0.4324\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4077 - val_loss: 0.4533\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3728 - val_loss: 0.4223\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4286 - val_loss: 0.4146\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3789 - val_loss: 0.4171\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3819 - val_loss: 0.5719\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4396 - val_loss: 0.4311\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5048 - val_loss: 0.4454\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3774 - val_loss: 0.4306\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4503 - val_loss: 0.4132\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5277 - val_loss: 0.5781\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6251 - val_loss: 0.5581\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4112 - val_loss: 0.4265\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5016 - val_loss: 0.9843\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4842 - val_loss: 0.4776\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5646 - val_loss: 0.4534\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4282 - val_loss: 0.4480\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4704 - val_loss: 0.4093\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3962 - val_loss: 0.4622\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4010 - val_loss: 0.4208\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5060 - val_loss: 0.5039\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.4092\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7027 - val_loss: 0.5968\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4427 - val_loss: 0.5514\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5686 - val_loss: 1.5376\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.2704 - val_loss: 1.1119\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6375 - val_loss: 0.8499\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6979 - val_loss: 0.5588\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6817 - val_loss: 1.2439\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5483 - val_loss: 0.6784\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.7511 - val_loss: 0.4165\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7431 - val_loss: 0.8650\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5189 - val_loss: 0.9666\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.4561\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4254 - val_loss: 0.4573\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3810 - val_loss: 0.4218\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4558 - val_loss: 0.4237\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4604 - val_loss: 0.7012\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5097 - val_loss: 0.4211\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4062 - val_loss: 0.5775\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6228 - val_loss: 0.5304\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5480 - val_loss: 0.4256\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4489 - val_loss: 0.4796\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4356 - val_loss: 0.4370\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5151 - val_loss: 0.4545\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3757 - val_loss: 0.4500\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6671\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6708 - val_loss: 0.4340\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7314 - val_loss: 1.3654\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6513 - val_loss: 0.6453\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5298 - val_loss: 0.7357\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6888 - val_loss: 0.4345\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8297 - val_loss: 0.5166\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4590 - val_loss: 0.4778\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3835 - val_loss: 0.5255\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4151 - val_loss: 0.4236\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3727 - val_loss: 0.4882\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4917 - val_loss: 0.4210\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4722 - val_loss: 0.7081\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4861 - val_loss: 0.4737\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4064 - val_loss: 0.5114\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - val_loss: 0.7110\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7822 - val_loss: 1.3249\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9439 - val_loss: 2.6424\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3251 - val_loss: 0.8806\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5710 - val_loss: 0.4061\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4158 - val_loss: 0.7979\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7338 - val_loss: 0.4202\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7979 - val_loss: 0.9948\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5436 - val_loss: 0.6780\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6208 - val_loss: 0.4658\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5062 - val_loss: 0.7587\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6218 - val_loss: 0.7278\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5692 - val_loss: 0.9404\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5928 - val_loss: 0.4201\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5693 - val_loss: 0.5956\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4182 - val_loss: 0.4153\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3547 - val_loss: 0.4078\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3674 - val_loss: 0.6753\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4231 - val_loss: 0.4366\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4802 - val_loss: 0.6180\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4255 - val_loss: 0.4167\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4374 - val_loss: 0.3936\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3922 - val_loss: 0.4854\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4509 - val_loss: 0.5838\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5236 - val_loss: 0.5100\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4548 - val_loss: 0.6905\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4627 - val_loss: 1.1510\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5993 - val_loss: 0.3890\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6297 - val_loss: 0.5519\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8359 - val_loss: 1.3064\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.3587 - val_loss: 1.1687\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7385 - val_loss: 0.4437\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4398 - val_loss: 0.4218\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6451 - val_loss: 0.4205\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9421 - val_loss: 0.4244\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7326 - val_loss: 0.6732\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.6392 - val_loss: 1.0726\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6883 - val_loss: 0.7776\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4388 - val_loss: 0.4838\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4535 - val_loss: 0.4944\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4476 - val_loss: 0.5172\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4686 - val_loss: 0.4563\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4221 - val_loss: 0.4483\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6108 - val_loss: 0.9791\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6729 - val_loss: 0.4482\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4390 - val_loss: 0.6767\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4775 - val_loss: 0.6289\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4151 - val_loss: 0.4234\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4061 - val_loss: 0.4104\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3757 - val_loss: 0.4656\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3881 - val_loss: 0.4128\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3499 - val_loss: 0.5343\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5047 - val_loss: 0.7668\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6044 - val_loss: 0.4606\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5338 - val_loss: 0.5207\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4372 - val_loss: 0.8584\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5685 - val_loss: 0.6924\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4812 - val_loss: 0.4083\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4115 - val_loss: 0.4882\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5353 - val_loss: 0.7178\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4247 - val_loss: 0.4355\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4430 - val_loss: 0.3865\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3932 - val_loss: 0.5368\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3796 - val_loss: 0.6433\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5543 - val_loss: 0.5069\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5008 - val_loss: 0.4314\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3973 - val_loss: 0.4189\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4131 - val_loss: 0.4054\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4677 - val_loss: 0.4060\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4562 - val_loss: 0.3920\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3728 - val_loss: 0.4501\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4072 - val_loss: 0.6645\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5707 - val_loss: 0.6008\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5713 - val_loss: 0.4781\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4519 - val_loss: 1.0372\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6521 - val_loss: 0.8164\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4698 - val_loss: 0.4444\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4721 - val_loss: 0.4016\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5417 - val_loss: 0.4606\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3676 - val_loss: 0.4584\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4600 - val_loss: 0.6757\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5792 - val_loss: 0.4461\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3770 - val_loss: 0.4353\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.5747 - val_loss: 1.6173\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0865 - val_loss: 1.0731\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6341 - val_loss: 0.5587\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3902 - val_loss: 0.4247\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3844 - val_loss: 0.5580\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3662 - val_loss: 0.4426\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3420 - val_loss: 0.4638\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3788 - val_loss: 0.7620\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4585 - val_loss: 0.7816\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5739 - val_loss: 0.4790\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7267 - val_loss: 0.8774\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7347 - val_loss: 1.1054\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5428 - val_loss: 0.5464\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3877 - val_loss: 0.4039\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4151 - val_loss: 0.4189\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3557 - val_loss: 0.3958\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3673 - val_loss: 0.4396\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3728 - val_loss: 0.4981\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4072 - val_loss: 0.4056\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4494 - val_loss: 0.5424\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4508 - val_loss: 0.6150\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5120 - val_loss: 0.4960\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4733 - val_loss: 0.5774\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4146 - val_loss: 0.5659\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4101 - val_loss: 0.4863\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3622 - val_loss: 0.5437\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4257 - val_loss: 0.4186\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5441 - val_loss: 0.6390\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3665 - val_loss: 0.4320\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4658 - val_loss: 0.4112\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4733 - val_loss: 0.5122\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4519 - val_loss: 0.5506\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4134 - val_loss: 0.4414\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6057 - val_loss: 0.8684\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3835 - val_loss: 0.5048\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4001 - val_loss: 0.3979\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3535 - val_loss: 0.4273\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3812 - val_loss: 0.4317\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3719 - val_loss: 0.4169\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3481 - val_loss: 0.4323\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3737 - val_loss: 0.4012\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3917 - val_loss: 0.4805\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4217 - val_loss: 0.9389\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.6441 - val_loss: 0.8541\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6672 - val_loss: 0.4135\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x293d8d690>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit model to training data with 30% validation split\n",
        "model_1.fit(X_train,\n",
        "            y_train,\n",
        "            epochs = TRAINING_EPOCHS,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            validation_split = 0.3)\n",
        "\n",
        "model_2.fit(X_train,\n",
        "            y_train,\n",
        "            epochs = TRAINING_EPOCHS,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            validation_split = 0.3)\n",
        "\n",
        "model_3.fit(X_train,\n",
        "            y_train,\n",
        "            epochs = TRAINING_EPOCHS,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            validation_split = 0.3)\n",
        "\n",
        "model_4.fit(X_train,\n",
        "            y_train,\n",
        "            epochs = TRAINING_EPOCHS,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            validation_split = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/12 [==============================] - 0s 1ms/step\n",
            "12/12 [==============================] - 0s 808us/step\n",
            "12/12 [==============================] - 0s 2ms/step\n",
            "12/12 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict next close with all models\n",
        "y1_pred = [val[0][0] for val in model_1.predict(X_test)]\n",
        "mse1 = mean_squared_error(y_true=y_test, y_pred=y1_pred)\n",
        "\n",
        "\n",
        "y2_pred = [val[0][0] for val in model_2.predict(X_test)]\n",
        "mse2 = mean_squared_error(y_true=y_test, y_pred=y2_pred)\n",
        "\n",
        "\n",
        "y3_pred = [val[0][0] for val in model_3.predict(X_test)]\n",
        "mse3 = mean_squared_error(y_true=y_test, y_pred=y3_pred)\n",
        "\n",
        "y4_pred = [val[0][0] for val in model_1.predict(X_test)]\n",
        "mse4 = mean_squared_error(y_true=y_test, y_pred=y4_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 955us/step\n",
            "28/28 [==============================] - 0s 1ms/step\n",
            "28/28 [==============================] - 0s 600us/step\n"
          ]
        }
      ],
      "source": [
        "y1_NDP = model_1.predict(X)[-1][0][0]\n",
        "y2_NDP = model_2.predict(X)[-1][0][0]\n",
        "y3_NDP = model_3.predict(X)[-1][0][0]\n",
        "y4_NDP = model_4.predict(X)[-1][0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(y_test)\n",
        "results_df.columns = ['y_actual']\n",
        "results_df['y1_pred'] = y1_pred\n",
        "results_df['y2_pred'] = y2_pred\n",
        "results_df['y3_pred'] = y3_pred\n",
        "results_df['y4_pred'] = y4_pred\n",
        "results_df.sort_index(inplace=True)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameters: [Training Epochs: 500 || Batch Size: 32 || Neurons: 256]\n",
            "Price forecast: model_1: MSE: 0.9369\n",
            "Price forecast: model_2: MSE: 0.4774\n",
            "Price forecast: model_3: MSE: 0.7565\n",
            "Price forecast: model_4: MSE: 0.9369\n"
          ]
        }
      ],
      "source": [
        "print(f'Hyperparameters: [Training Epochs: {TRAINING_EPOCHS} || Batch Size: {BATCH_SIZE} || Neurons: {NEURON_CT}]')\n",
        "print(f'Price forecast: model_1: MSE: {mse1:.4f}')\n",
        "print(f'Price forecast: model_2: MSE: {mse2:.4f}')\n",
        "print(f'Price forecast: model_3: MSE: {mse3:.4f}')\n",
        "print(f'Price forecast: model_4: MSE: {mse4:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = [x for x in range(len(y_test))]\n",
        "plt.plot(results_df.y1_pred, '.b', label='Model 1')\n",
        "plt.plot(results_df.y2_pred, 'xg', label='Model 2')\n",
        "plt.plot(results_df.y3_pred, '.r', label='Model 3')\n",
        "plt.plot(results_df.y4_pred, '+y', label='Model 4')\n",
        "plt.plot(results_df.y_actual, '--k', label='Actual')\n",
        "plt.title(f'Next Day Close Prediction.\\n Actual: \\${results_df.y_actual.iloc[-1]:.2f} | Model 1: \\${y1_NDP:.2f} | Model 2: ${y2_NDP:.2f} | Model 3 ${y3_NDP:.2f} | Model 4: ${y4_NDP:.2f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "y1_diff = (results_df.y_actual.sub(results_df.y1_pred))\n",
        "y2_diff = results_df.y_actual.sub(results_df.y2_pred)\n",
        "y3_diff = results_df.y_actual.sub(results_df.y3_pred)\n",
        "y4_diff = results_df.y_actual.sub(results_df.y4_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Report maximum error for prediction date - index + 1\n",
        "y1_idxmax = y1_diff.abs().idxmax().date() + timedelta(days=1)\n",
        "y1_errmax = y1_diff.abs().max()\n",
        "y2_idxmax = y2_diff.abs().idxmax().date() + timedelta(days=1)\n",
        "y2_errmax = y2_diff.abs().max()\n",
        "y3_idxmax = y3_diff.abs().idxmax().date() + timedelta(days=1)\n",
        "y3_errmax = y3_diff.abs().max()\n",
        "y4_idxmax = y4_diff.abs().idxmax().date() + timedelta(days=1)\n",
        "y4_errmax = y4_diff.abs().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_label = 'Model 1'\n",
        "plt.bar(results_df.index, y1_diff, color='blue', label=plot_label)\n",
        "plt.title(f'Test Data Error for {plot_label}.')\n",
        "plt.ylabel('Error ($)')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_label = 'Model 2'\n",
        "plt.bar(results_df.index, y2_diff, color='green', label=plot_label)\n",
        "plt.title(f'Test Data Error for {plot_label}.')\n",
        "plt.ylabel('Error ($)')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAElCAYAAADz3wVRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAApBUlEQVR4nO3deZxcVZn/8c+XEAhLAoQEBEISVBQIBPDXAiIioOwIOMIPIggIGBhHZdwQ1BFUBFzGbXAEdBxQIIAogyMismUYUMAEQggiisgSwpIEkMWELc/8cU6Tm6Kqum53V9+q5Pt+verVfbdznrvUfe5W5yoiMDMza9VKVQdgZmbdxYnDzMxKceIwM7NSnDjMzKwUJw4zMyvFicPMzEpx4jCriKT3SnpY0nOStq06nkYkhaQ3tjDeLpLmDkVMVi0njhVc3mn1fpZIWlToPqwf5U2XdGyT4RPzjqi3jscl/VLS7iXqOErSTWVjK0y/S57X52o+b+tvmf30DeAjEbFmRNwx0MLysg9JW9f0vzz332WgdQyEpBskzZf0jKQ7JR1QZTzWf04cK7i801ozItYEHgLeU+h3YRurXjvXuTVwDXC5pKPaWF+tecV5z5/f1Y6kZKWafiuXqajJ+BOAu8uUVShzWINBfwKOKIy3LvA2YH5/6hlkJwAbRMQoYCpwgaQNKo7J+sGJw+qStJKkkyT9RdJCSZdKGp2HjZB0Qe7/tKTfS1pf0leAdwBn5SP4s/qqJyIei4jvAKcCX+3dSRfqflbSHyS9N/ffHDgbeFuu4+ncf19Jd+Sj2YclnTqAeZ8u6SuSbgb+Drw+H7H/k6Q/A3/O431I0n2SnpT0C0kbFsp4zfiFYatKeg4YBtwp6S+985brflrS3ZL2L0xznqTvS/qVpOeBXRuEfyFwSCGxTAEuB16sqf/bkublz7clrVoY/mlJj+ZhR9eJ/RuSHspni2dLWq2V5RoRsyPi5d5OYDiwcSvTWoeJCH/8ISIAHgDenf8/AbgFGAesCpwDTMvDjgP+G1idtPP7f8CoPGw6cGyTOiaSdhor1/R/fe6/ee4+GNiQdHBzCPA86WgV4CjgpprpdwG2yuNPBh4HDmwQwy7A3CYxTiedfU0CVibt4IJ0ZjQaWA3YDVgAvCUvn38DbiyUscz4DeoJ4I35/+HAfcBngVVy+c8Cb87DzwP+Brw9z+OIBnEfC/wG2Dv3u410xjEX2CX3+1Jet+sBY4HfAl/Ow/bKy25LYA3gopo4vwX8Is/XyLwdnNHKcs3j/BJYnMv8NbBS1du9P+U/PuOwRo4HPhcRcyPiBdIZwUH5sstLwLqknckrETEzIp4ZYH3z8t/RABHx04iYFxFLIuIS0lH7do0mjojpEXFXHn82MA14Z5P6NsxH9sXPGoXh50XE3RHxckS8lPudERFPRsQi4DDgRxFxe14+J5POgiYWyiiO35cdgDWBMyPixYi4nrSTnVIY54qIuDnP4+ImZf0YOELSZqRLgrWX4A4DvhQRT0TEfOCLwAfysP8P/GdEzImI50nrHUiX7UiXmD6e5+tZ4HTg0BbmD4CI2I+UcPYBfhMRS1qd1jpHqWu1tkKZQLrvUPxivwKsD/yEdInhYklrAxeQksxLrymldRvlv08CSDoC+ATpDAXSTnVMo4klbQ+cSTpSXoV0FvDTJvXNi4hxTYY/3Ee/DYHbezsi4jlJC/N8PNCkjEY2BB6u2ZE+yNLlUqa8nwP/Ciwkrat6dT1YU8+GhWEza4b1Gks6y5yZcggAIp11tixvJ1dJOkHSfRHxizLTW/V8xmGNPEy63LF24TMiIh6JiJci4osRsQWwI7AfS2/I9re55fcCTwD3SpoA/AD4CLBuRKwNzCHtpBrVcRHpEsrGEbEW6T6I6ozXqnp1FPvNIyVXAPLZyrrAI32U0cg8YOOaG/Hj+1NeRPwduAr4R+onjmViz/X0nvE9yrL3HcYX/l8ALAImFbaJtSI95NAfKwNv6Oe0ViEnDmvkbOAreSeOpLG9j09K2lXSVvkG7DOkS1e9R8qPk+5XtCTfVP8IcApwcj7iXoO0k5yfx/kg6Uyi1+PAOEmrFPqNBJ6MiMWStgPeX3qOy5kGfFDSNvnG8unArRHxQD/Lu5V0I/5EScPzo7PvAS7uZ3mfBd7ZIJ5pwOfzOh0DfIF01ghwKXCUpC0krU5aLwDkdfMD4FuS1gOQtJGkPfsKRtJmkvaWtFqev8OBnYH/6ef8WYWcOKyR75CO4H8j6VnSzdTt87DXAZeRksY9pC//TwrTHSTpKUnfbVL+0/npoLtI17sPjogfAUTEH0iXWn5HShJbATcXpr2e9BjrY5IW5H4fBr6UY/0CaQfYzIZ67e843tfHNK+KiGuBfwF+RjpKfwMlrvXXKe9FUqLYm3Rk/+/AERHxx36WNy8iGv3W5TRgBjCbtPxvz/2IiKuAb5OW8X35b9Fncv9bJD0DXAu8uYWQRLpf8gTpgOAE4JCIuB1A0jvyk2bWBRThFzmZmVnrfMZhZmalOHGYmVkpThxmZlaKE4eZmZWy3CeO/LRMy4+H2qutz+5SdRzLCy1tEbjuD24lvVnSrNwu18faFEPTVosHqY4BtVps3aPSxCHpAUkv5mfJi/3vyF+0iQOtI1Krp/cPtJzBlhute7HmcdA7q46rEUljJN2spQ0b/k7S25uMv5GkK5QaAJwr6fia4btJul2pUcL7JU1t/1z0j6RTJV3Q95j9diJwQ0SMjIhmjzC3ZAjiXe4oNZJ5U962H5P0Q0kjC8NXlfSjvL0+JukThWE7SLomb+vzJf1UhVZ/lXw1f3cW5v8b/ji1WV15+OqS/l3SAkl/k3Rjk7JWkXRZ3te+pml9pd9k3ZDLeaDV5dUJZxx/pdAej6StSM0arAi+Fss26711vZHqHak2OnptpJXx85Hv9cB3gV9ImiFpkzz4OeBoUrMT6wBfBf67SbkXkNbt+sC+wOmSds31DCe12HoOsBapEcNvquY9EgOZl8EyRHUNpHl1Nxs0ONYi/ZZlQ2BzUlMvXy8MPxXYlLSudiX9UHOvPGwd4FxS8zgTSI1T/mdh2qnAgaRXCEwm/V7nuCaxNKuLXNfoHOdo4ON9zNtNwOHAY3WGPQ/8CPh0H2Usq8oWFklt+nwe+H2h3zeAz5F+OTwx99sXuIP0g7OHgVML4x9C2kH1ts66d15AY3N3sWXP80g/rLqKtCO8mfRjtm8DTwF/BLYtlP3qtIXpT8v/70JqcfRE0o+aHiVtHPuQ3onwJPDZJvP+all1hk3MdR9DaqX1RlKLsDeTWiddSNrI1yI1aDef1KbQ58mtjdYbv4X1cTXpB3wfAnYnNby3fp3xViJt/AGsV2f4mnnY2EK/c4Gf5P/Xz8NXLwz/PTClQVynkn5weEHeBo7N8/4febk/kpfHsJp5P4vUouwfgXcVytuQ9OPGJ0k/ZvtQk7o+QmqS/KW8zdyZx2tW/zDSdrwAuB/4J+q0CJzHvZ7UBtjiXP6bBrJeSa3b1ot3OvDlPO2zpBZ0xxSm24HUSu7TwJ3klnQbrI+NSe1hzc8xnFWI7abCeDvm9fq3/HfHwrCj8rJ5lvT9Paww7GjSD0ufIm2TE5rEsj8p6T6d53Hzmv3Lp0g/dPwbcAl1WhVuUO4/AHcVuucBexS6vwxc3GDatwDPFrp/C0wtdB8D3NKk7oZ1AZuRtstRrcxHTbmvtpBcZ9i7gQdaLqts5YP5ySv23cC9pOw5LM/cBJZNHLvQpMls0jsIziO1FTQP2K8wrDZxLCA1Az6C9KX9K6mdpWGkL/8N9aYtTF9MHC+TfqU8nLSznU9qM2kkqUnuRcAmDeb91bLqDJuY6/4xqfmN1UhftJeBj5La+FktD78i1zeRlLCOKXwxa8d/PzC7yfqYRWo59agmG9hs0o4pgB80GGckNUmF1FTFHYXui0g71GGkZr+fILUzVa+8U0k7wgPzNrAaS89Y1iA1D34bcFzNvH88r5tDSDuO0Xn4jaQDiBHANnm97dakrlOBC2pialb/8aRktTHpiPAGGiSOPP50Ck3Rl12vDZZXbbzTgb+QEtNqufvMPGwjUgLYJ8/z7rl7bJ2yh5ESy7fyvI8AdirEdlP+fzRpx/+BHOeU3L1unu4ZljYZvwGp/SuAA0jJfPM83eeB3zZYbm8iHTHvntfziXnaVQr7l9tIBwqjScno+Bb3Td9m6c56nbz+1i8MP4hCYqmZ9p8pJAbStrd9obuHQmKpmbZpXaR91V15+S/I/7+vxXla7hLH54EzSEdL1+QN5tXE0WClfqvQvTbpyPwu4JyacWsTxw8Kwz4K3FPo3gp4ut60hemLiWMRS48ye3eWxQ1kJo3fCXEe6Sjz6cLn/DxsYi7r9YXxjwIeqvkCvwhsUeh3HDC93vgtro8jSEfht5OOmBst/xGkHcGRTcq6ifSOihGkI7AngXsLw99DOgB4OX8+1KSsU1n2XRfrAy9Q2GnmeG4ozPs8cssIud9tpJ3YxqQj/JGFYWeQmlF/TV2FfheUqP96CjsoYA9aTByDsV5r4y3U8flC94eBX+f/P0M+GywMv7re+mXp2wTrnT0dxdLE8QHgtprhv8vjrEHa3t9HTeIjXQ04ptC9EqkNrwl16vsX4NKacR9h6XtHHgAOLwz/GnB2C9+D3UlJ7k25e+O8/kbUjPNAnWknk7b1dxT6vQJsVujeNJenOtM3rYvUBlnkdbwK6dUBz1E402oyX4OWODrhHgekdo7eT9qoflw7UNL2Wvq+4r+RjuhevaEeEU+TmtDektTGUTOPF/5fVKe7TEufCyPilcK09cpvVt43YtnWZ4+sGV7bjHaxewzpKKu2eez+NMMNQET8mLTh30I6KrpLdd4LHRGLI2IacFKT+xKHAZvkGL5PuvQzF1KDd6TG+44gbfyTSNdx920SXnFeJpDm/dF8M/Np0tH/eoVxHon8jch6mw7fkNQY4rM1w8ost77q37CmjAdp3aCv14LiNe6/s3TbnAAcrMK7SYCdSGcCtTYGHoylb/JrpLbpdnL3RpHe83EI6Xv8qKQr8zbRG8t3CnE8SWrnaiNea5k6IjXC+HDNuI3muS5JO5DOhg+KiD/l3r1taI0qjDqKdJmtOO0bSYnvhIj438Kg5+pM+1xEhNIbFHsfjvlsC3UtIp0RnxbpvS3/Qzqj3UPS+OLDNs3mc6A6InFExIOkS0b7kK6d1mraZLakbUjXRaeRbuwOlr+z7I361w1i2a2IJt0LSBvQhEK/fjXDvUwFEXNJR+enklp8/VCT0YfToCXciHgwIvaLiLERsT1ph3hbHrwl8KeIuDrSS4nuBa4k3Z9qGFrh/4dJR/xjCkl3VERMKoyzUc2TK71Nh88DRhefmKHv5Vbb3Vf9zZom78tgrNey6/1h0hlH8SBmjYg4s8G441u4KV/bdDsU5iOv+91JyemPpEuZveUfVxPLahHx277qyOt7Y5ZdVi2TtC1pP3N0RFzX2z8iniKt0+JB0tYUHmhQakX6WtKbFGubsr+70bQRcXwsfTjm9Bbqml0n9MhlPVQoq79N3bekIxJHdgzpOvPzdYY1bDJb0gjS0exngQ+SdhgfHqSYZgHvlzQsP9XwzkEqd8Dymc6lpKbPR+YN9xMsbR67NElHFnaow0jXmR/Pw3aQtFN+vG81SZ8hXbK5tUFZm+e4VlFqQnsP4Jt58B3ApkqP5ErSG0jv9Kj3pXiNiHiUdHP3XyWNUno/+hskFdfPesDHlJrwPjjPy68i4mHSzcozlN6dPpm07TVbbo8DE5XfldFC/ZfmusdJWgc4qZX5ymUPxnpdJt4WXAC8R9KeeVsfIWkXSfVedHUbacd2pqQ18rj1Hsv+FfAmSe+XtLKkQ4AtgF8qNaV/gNI7TF4gHWX3Nst/NnCypEkAktbK66+eS4F9Jb0rP6n3yVxevSTTlKQtSa+y/WhE/HedUX5Maop+nXx29CHS5WYkbUS6PHlWRJzdYNpPKD2ivmGO87wm4TSsi3R/7iHSMlo5L/tdSZcWG83bqnk/CbBKXmfKw1bKw4anTo3Qsq8rqKtjEkdE/CUiZjQY3KzJ7DNIb077fqRXeB4OnCZp00EI6wTStfinSZde/msQyiw6Ucv+jmNB35Ms46Okm4P3k+4pXER6tK4uSYdJavbY55tJO/Wvky79vY50HRnSG/W+R7pp+gjp7HDfiJjXoOw9c1xPkS5J7BXpNaVExF9IZ4jfJd0k/R9S8+Q/bHXGWXqZ6w+5jstY9tLKraRryQuAr5AuPSzMw6aQ7iPNI93kPiVSM+mN9L5JcKGk3rf+Nav/B6Qv8p2k+0X1zqKbKbVeW4y3oZxMDyAdfM0nHfV/mjr7h5zY3gO8kbQDm0u67FQ73kLSwcAnSdvMiaSHVhbkcj9BWv5Pkg7I/jFPdznpUe+LlZptn0ODM9F8pno46V7aghzXeyI1UV/WJ0mPmv9H4ftY3J5PIT1c8CBpe/16RPw6DzuWdOZ9aoNLReeQ3s1+V56fK3O/RhrWFentiQeQvn9/I21rfTW/fy/pEtdGpO1yEUvP1HbO3b8inREuIh0UNeVm1e01JB1FulE2veJQ+iXHf2xE7FR1LGbLo4454zAzs+7gX53aa0TEeVXHYGady5eqzMysFF+qMjOzUrrqUtWYMWNi4sSJVYdhZtZVZs6cuSAixg5WeZUljvzs8I2kxzxXBi6LiFOaTTNx4kRmzGj0xK6ZmdUjqUzrBX2q8ozjBdIP/p7LP965SdJVEXFLhTGZmVkfKkscuR2h3h/JDM8f36k3M+twVb8BcJikWaQmta+JiNc0XyFpqtILhWbMnz9/yGM0M7NlVXpzPDdfsI2ktYHLJW0ZEXNqxjmX9BIgenp6fEZitoJ56aWXmDt3LosXL646lI43YsQIxo0bx/Dhw9taT0c8VRURT0u6gfQ+jjl9jW9mK465c+cycuRIJk6ciBq/qnuFFxEsXLiQuXPnsskmm/Q9wQBUdqlK0th8poGk1UgvK2nWUJeZrYAWL17Muuuu66TRB0msu+66Q3JmVuUZxwbA+ZKGkRLYpRHxywrjMbMO5aTRmqFaTlU+VTUb2Laq+s3MrH/c5IiZdRdpcD8tVSkOP/zwV7tffvllxo4dy3777Vcq9IkTJ7JgQfPX7jQaZ6+99mLrrbdm0qRJHH/88bzyyit1ph4aThxmZn1YY401mDNnDosWLQLgmmuuYaON6r0GvX0uvfRS7rzzTubMmcP8+fP56U9/2vdEbeLEYWbWgn322Ycrr7wSgGnTpjFlypRXhz355JMceOCBTJ48mR122IHZs9NbkBcuXMgee+zBpEmTOPbYYym2Rn7BBRew3Xbbsc0223Dcccf1eQYxatQoIJ3tvPjii5Xe93HiMDNrwaGHHsrFF1/M4sWLmT17Nttvv/2rw0455RS23XZbZs+ezemnn84RRxwBwBe/+EV22mkn7r77bt773vfy0EMPAXDPPfdwySWXcPPNNzNr1iyGDRvGhRde2GcMe+65J+uttx4jR47koIMOas+MtqAjfsdhZtbpJk+ezAMPPMC0adPYZ599lhl200038bOf/QyA3XbbjYULF/LMM89w44038vOfp1fO77vvvqyzzjoAXHfddcycOZO3vvWtACxatIj11luvzxiuvvpqFi9ezGGHHcb111/P7rvvPpiz2DInDjOzFu2///586lOfYvr06SxcuLDf5UQERx55JGeccUbpaUeMGMEBBxzAFVdcUVni8KUqM7MWHX300ZxyyilstdVWy/R/xzve8eqlpunTpzNmzBhGjRrFzjvvzEUXXQTAVVddxVNPPQXAu971Li677DKeeOIJIN0jefDBxi2fP/fcczz66KNAusdx5ZVXstlmmw36/LXKZxxm1l0qfN31uHHj+NjHPvaa/qeeeipHH300kydPZvXVV+f8888H0r2PKVOmMGnSJHbccUfGjx8PwBZbbMFpp53GHnvswZIlSxg+fDjf+973mDBhQt16n3/+efbff39eeOEFlixZwq677srxxx/fvhntQ1e9c7ynpyf8IiezFcs999zD5ptvXnUYXaPe8pI0MyJ6BqsOX6oyM7NSnDjMzKwUJw4z63jddEm9SkO1nJw4zKyjjRgxgoULFzp59KH3fRwjRoxoe11+qsrMOtq4ceOYO3cufnV033rfANhuThxm1tGGDx/e9jfaWTm+VGVmZqU4cZiZWSlOHGZmVooTh5mZleLEYUOrwpfPLJe8PK0ClSUOSRtLukHSHyTdLemEqmIxM7PWVfk47svAJyPidkkjgZmSromIP1QYk5mZ9aGyM46IeDQibs//PwvcAwzt29/NzKy0jrjHIWkisC1wa51hUyXNkDTDvxw1M6te5YlD0prAz4B/johnaodHxLkR0RMRPWPHjh36AM3MbBmVJg5Jw0lJ48KI+HmVsZiZWWuqfKpKwH8A90TEN6uKw8zMyqnyjOPtwAeA3STNyp99KozHzMxaUNnjuBFxE+BfL5mZdZnKb46bmVl3ceIwaxc3B2LLKScOMzMrxYnDzMxKceIwM7NSnDjMupHvn1iFnDjMzKwUJw4zMyvFicPMzEpx4jAzs1KcOMxsYHyjfoXjxGFmZqU4cZgtD3zUb0PIicO6i3eQZpVz4jAzs1KcOKw1PtI3s8yJwwbOScVsheLEYWadzQcmHceJw8zMSnHiMDPri896llFp4pD0I0lPSJpTZRy2nPGX3DrNcrZNVn3GcR6wV8UxmA2u5WwnYVar0sQRETcCT1YZgy0nanfW3nkPjJefNVH1GUefJE2VNEPSjPnz51cdjpnZCq/jE0dEnBsRPRHRM3bs2KrDsRWZj8JtsHT5ttTxicNWAF3+JTJb0ThxmC2vnJCtTap+HHca8DvgzZLmSjqmynisy3jHaFaJlausPCKmVFm/WUMSRFQdhXWTFWib8aUqM7NO1MFn1E4cZmZWihNHp+jgowuzrufv16By4mgHb6Rmthxz4lgRObGZ2QA4cZiZWSlOHGa2fPCZ9JBx4jAbCO+sbDC2gS7bjpw4zMysFCcOa692H0l12ZGadTlvb4ATR+u8wZh1D39f28qJY6j4DXVmtpxw4ug2TjidabDXi9ezdTAnDutc3nkOnaFa1l6nywUnDjMzK8WJw8zMSnHiMDOrx5fVGnLiMLPB4R3tCsOJw5Ll8Uu/PM6TWQdw4ijLOyMzW8FVmjgk7SXpXkn3STqpylisIk7EZl2nssQhaRjwPWBvYAtgiqQtqopnQLzzMxsc/i51hSrPOLYD7ouI+yPiReBi4IAK4zEzsxas3NcIksYBhwLvADYEFgFzgCuBqyJiST/r3gh4uNA9F9i+n2WZmS2/JIioOopXNT3jkPSfwI+AF4GvAlOADwPXAnsBN0nauZ0BSpoqaYakGfPnzx9oYc27m+ldafVWXm8/aekKri27drq+uhvF2erG02zems1DmWn6M6xed6Ppi/1756fYrzhtvf615TZa//WWVV/rubZfbf2NymhVq+ujle2ynuI81Ntmy8TeKIZWl2u9evsTS711ULaMRvW2spybzVt/vv/N5qdifZ1x/GtEzKnTfw7wc0mrAOP7WfcjwMaF7nG53zIi4lzgXICenp7OWnpmZiugpmccDZJGcfiLEXFfP+v+PbCppE1yAjoU+EU/yzIzsyHS581xSbvm+xxImiDpWkm3DPQSVUS8DHwEuBq4B7g0Iu4eSJlm/dJhlwHMOl2fN8eBM4F35/9PBy4D7gC+D7xlIJVHxK+AXw2kDDMbJE6g1qKmiUPSKaT7EB+XJGBP4H5gfWCMpC8A0yPixrZH2g3q3RS3weGdmnWj5XS7bZo4IuKLkvYGbgDWA34bEf8CIGmPiPjSEMRoZmYdpJVLVZ8Evgm8AEwFkDQJmNW+sMzaYDk9+jMban0mjoi4mZof5uWb2P/UrqC6mndOZgPn71FH6+sHgDv1MXyUpC0HNyQzM+tkfZ1xvE/S14BfAzOB+cAI4I3ArsAE0qUsq+UjpuWX162t4Pq6Of5xSaOB9wEHAxuQ2qq6BzgnIm5qf4hmbeIEYNYvrdzjeBL4Qf6YmbWmP21MWVfwGwCXV/4ympXn701LnDjMzKyUVtqqWknSjkMRjJmZdb4+E0d+UdP3hiAWMzPrAq1eqrpO0vtye1VmZrYCazVxHAf8FHhR0jOSnpX0TBvjsiLfsDOzDtJKW1VExMh2B2JmZt2hpcQBIGl/oPflTdMj4pftCcnMzDpZS5eqJJ0JnAD8IX9OkHRGOwMbEr4EZCsqb/s2AK2ecewDbJOfsELS+aS3AJ7crsDMbIg4iVhJZX4AuHbh/7UGOQ4zM+sSrZ5xnA7cIekGQKR7HSe1LSozM+tYfSYOSSsBS4AdgLfm3p+JiMfaGZiZmXWmVn85fmJEPBoRv8ifASUNSQdLulvSEkk9AynLzMyGVqv3OK6V9ClJG0sa3fsZQL1zgH8AbhxAGWZmVoFW73Eckv8W3zMewOv7U2lE3APgFkzMzLpPq/c4ToqIS4Ygnnr1TwWmAowfP76KEMzMrKDVexyfLluwpGslzanzOaBMORFxbkT0RETP2LFjy4ZhZmaDrNVLVddK+hRwCfB8b8/8Wtm6IuLdA4zNzMw6UCX3OMzMrHu12jruJoNZqaT3Av8GjAWulDQrIvYczDrMzKw9mt7jkHRi4f+Da4ad3t9KI+LyiBgXEatGxPpOGmZm3aOvm+OHFv6vbdBwr0GOxczMukBfiUMN/q/XbWZmK4C+Ekc0+L9et5mZrQD6ujm+dX63uIDVCu8ZFzCirZGZmVlHapo4ImLYUAViZmbdocyLnMzMzJw4zMysHCcOMzMrxYnDzMxKceIwM7NSnDjMzKwUJw4zMyvFicPMzEpx4jAzs1KcOMzMrBQnDjMzK8WJw8zMSnHiMDOzUpw4zMysFCcOMzMrpZLEIenrkv4oabakyyWtXUUcZmZWXlVnHNcAW0bEZOBPwMkVxWFmZiVVkjgi4jcR8XLuvAUYV0UcZmZWXifc4zgauKrRQElTJc2QNGP+/PlDGJaZmdXT9J3jAyHpWuB1dQZ9LiKuyON8DngZuLBRORFxLnAuQE9PT7QhVDMzK6FtiSMi3t1suKSjgP2Ad0WEE4KZWZdoW+JoRtJewInAOyPi71XEYGZm/VPVPY6zgJHANZJmSTq7ojjMzKykSs44IuKNVdRrZmYD1wlPVZmZWRdZsRKH78GbmQ3YipU4zMxswJw4zMysFCcOMzMrxYnDzMxKceIwM7NSnDjMzKwUJw4zMyvFicPMzEpx4jAzs1KcOMzMrBQnDjMzK8WJw8zMSnHiMDOzUpw4zMysFCcOMzMrxYnDzMxKceIwM7NSnDjMzKyUShKHpC9Lmi1plqTfSNqwijjMzKy8qs44vh4RkyNiG+CXwBcqisPMzEqqJHFExDOFzjWAqCIOMzMrb+WqKpb0FeAI4G/Ark3GmwpMBRg/fvzQBGdmZg0poj0H+5KuBV5XZ9DnIuKKwngnAyMi4pS+yuzp6YkZM2YMYpRmZss/STMjomewymvbGUdEvLvFUS8EfgX0mTjMzKx6VT1VtWmh8wDgj1XEYWZm5VV1j+NMSW8GlgAPAsdXFIeZmZVUSeKIiPdVUa+ZmQ2cfzluZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZlVJp4pD0SUkhaUyVcZiZWesqSxySNgb2AB6qKgYzMyuvyjOObwEnAlFhDGZmVlIliUPSAcAjEXFnFfWbmVn/rdyugiVdC7yuzqDPAZ8lXaZqpZypwFSA8ePHD1p8ZmbWP4oY2itFkrYCrgP+nnuNA+YB20XEY82m7enpiRkzZrQ5QjOz5YukmRHRM1jlte2Mo5GIuAtYr7db0gNAT0QsGOpYzMysPP+Ow8zMShnyM45aETGx6hjMzKx1PuMwM7NSnDjMzKwUJw4zMyvFicPMzEoZ8t9xDISk+cCDbSh6DNBNjwN3U7zdFCt0V7zdFCs43nZrFu+EiBg7WBV1VeJoF0kzBvPHMe3WTfF2U6zQXfF2U6zgeNttKOP1pSozMyvFicPMzEpx4kjOrTqAkrop3m6KFbor3m6KFRxvuw1ZvL7HYWZmpfiMw8zMSnHiMDOzciKi6z7AxsANwB+Au4ETcv/RwDXAn/PfdXL/w4DZwF3Ab4GtC2XtBdwL3Aec1KTOI3O5fwaOzP1GArMKnwXAt9sc74+AJ4A5fSyjuvMFfCT3C2BMh8f6v4VlOw/4r3bF26icTly2gxTrUC7bEcBtwJ25nC+W+Z7l/l8BHgaea/d+YaDxUsF+IQ8fBtwB/LIdy3eZcloZqdM+wAbAWwor6U/AFsDXer8cwEnAV/P/OxYW/t7ArYUF/Rfg9cAqeUPZok59o4H789918v/r1BlvJrBzu+LN3TsDb6HJzrjZfAHbAhOBB6i/c+uYWGvG+xlwRBu3hbrldOKyHYxYh3jZClgz/z8cuBXYocz3DNghx9MscXRMvEO9X8j9PgFcRIPEMdDlu0xZrYzU6R/gCmB30pHVBoWVcm+dcdchve8c4G3A1YVhJwMn15lmCnBOofscYErNOG8iZWy1K95Cv4k03xn3OV802Ll1aKyjgKeAUe2Ot7acTl62gxTrkC5bYHXgdmD7OsNa+Z61tGProHiHZL9AepPqdcBuNE4cg7Z8u/4eh6SJpCO9W4H1I+LRPOgxYP06kxwDXJX/34i0UnvNzf1qtTLeocAlkZd+m+JtVavz1VQHxXogcF1EPDMU8daU0594+9RBsR7IECxbScMkzSJdurwmItq2bDss3qHaL3wbOBFY0qSaQVu+lb/IaSAkrUk6zf7niHhG0qvDIiIkRc34u5IW+E5tCOdQ4APNRuiweJvqsFinAD9sNsJgxVtbzuCE39GxDsmyjYhXgG0krQ1cLmnLiJjTz5ib6rB4275fkLQf8EREzJS0Sz9iLK1rzzgkDSct7Asj4ue59+OSNsjDNyAdLfSOP5n0BTkgIhbm3o+QblD1Ggc8Iml7SbPyZ/9G4xXK3hpYOSJmtjneRmVvXIj3+L7i7UsnxSppDLAdcGW7461XTqcu28GIdSiXba+IeJp0Q3ivst+zVnRSvEO4X3g7sL+kB4CLgd0kXdCO5fuqVq5nddqHdPPqx9Q8qQB8nWVvKn0t/z+e9FTJjjXjr0y6QbQJS28eTqpT32jgr6Triuvk/0cXhp9J8ycvBiXewnQTaX7foM/5ovEN3I6KFTgeOH8ItoW65XTish2sWIdw2Y4F1s7/r0Z6omu/st+zPE6zm+MdFS9DvF/I4+xC85vj/V6+y4zXykid9iGdogXp0bRZ+bMPsC7pBtGfgWt7FwopQz9VGHdGoax9SE8z/AX4XJM6j84r7T7ggzXD7gc2G6J4pwGPAi+RrlEe06DOuvMFfCxP9zLpMcwfdmqsedh0YK92L9tG5XTish2MWId42U4mPSY6G5gDfKHs94z0pNFc0jX8ucCpnRzvUO8XCmXuQvPHcfu9fIsfNzliZmaldO09DjMzq4YTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHWQOSXsk/nrpb0p2SPimp6XdG0kRJ7x+qGM2q4MRh1tiiiNgmIiaRGp/bGzilj2kmAk4ctlzz7zjMGpD0XESsWeh+PfB7YAwwAfgJsEYe/JGI+K2kW4DNSb/KPR/4LukXxLsAqwLfi4hzhmwmzNrAicOsgdrEkfs9DbwZeBZYEhGLJW0KTIuIntzI3KciYr88/lRgvYg4TdKqwM3AwRHx1yGcFbNB1dWt45pVaDhwlqRtgFdI712oZw9gsqSDcvdawKakMxKzruTEYdaifKnqFVJrpacAjwNbk+4VLm40GfDRiLh6SII0GwK+OW7WAkljgbOBsyJd310LeDQilpDetzAsj/os6TWgva4G/jE3n42kN0laA7Mu5jMOs8ZWU3oL3HBSi7c/Ab6Zh/078DNJRwC/Bp7P/WcDr0i6EzgP+A7pSavbld7QM5/01j2zruWb42ZmVoovVZmZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV8n/ZzfABBUEUGwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_label = 'Model 3'\n",
        "plt.bar(results_df.index, y3_diff, color='red', label=plot_label)\n",
        "plt.title(f'Test Data Error for {plot_label}.')\n",
        "plt.ylabel('Error ($)')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAElCAYAAADz3wVRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsMUlEQVR4nO3dd7xdVZn/8c83BQKhGEhAICTBERTQAE4EBpAJRURwKDM4EhgBAREdlZ+iWAABC3ZUFEYYCz2gFBuiIhIQxZJIiEEElBpqCDWYMIQ8vz/WOsm+h9N27j0t+b5fr/O6d7e1nr3PPvvZdW1FBGZmZq0a1u0AzMysvzhxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpThzWFySFpFcOcZkzJB09lGX2MklrSPqxpKclfb/b8dQj6VRJF7U47ir1HfYKJ44eI2lh4bNU0qJC96ErUF7DH5akSXmjXKnjUUk/kfTGEnUcIemmsrHVKGezPM//M9iyhtpgN1B5+sVV3++PhzLGFhwEbAisHxFvHWxhkqbmdeeqqv7b5P4zBlvHUJF0XY5pRLdjWRk4cfSYiFir8gHuB/6t0O/iNlb9slznNsC1wFWSjmhjfbUcBjwJvE3S6h2uuxPeW/x+I+Lfao1Ua+NWdoNXZ/yJwJ0RsaRMWU3qnw/8i6T1C/0OB+4sW0e75B2ukd2OY2XixNEnJA2T9FFJf5e0QNL3JK2Xh42SdFHu/5SkP0raUNJngDcA38h7uN9oVk9EPBIRXwNOBT4vaViuo1L3s5L+IunA3H9L4JukjcdCSU/l/vtKukXSM5IekHRqk/kTKXGcBLwA1Nqo7iPpbkmPS/piIbZXSrohn4J5XNJlhXJ3ysvj6fx3pzr1Dzg9UjgSG1FvOUp6taRrJT0h6Q5J/9ls+dape6qkeZI+IukR4Ls5nsvz9/oMcISkjSX9KNf3N0nvrIp/wPhVdZwGfIKUlBdKOiqvUydJuk/SY5IukLRu1fwfJel+4Fd1wv8/4AfAwXm64cDbgAE7OY2+h3ykeUNet64FxlZNu6Ok3+Z1+1ZJU0ss23WBU4ATWp3GWhAR/vToB7gX2DP/fxzwO2A8sDpwDjA9D3sX8GNgTWA48M/AOnnYDODoBnVMAgIYUdX/Fbn/lrn7rcDGpJ2NtwHPARvlYUcAN1VNPxV4bR5/MvAocECDON4APA+MAb4O/LhqeADXA+sBE0h7tEfnYdOBE3Ndo4Bdcv/1SEcwbwdGANNy9/rVy4aUKC+qt1yqlyMwGngAeEcuezvgcWCrOvNX93vIy2oJ8Pn83a6R43kBOCDP1xrAjcDZeR63Je3t716If8D4Neqpnscjgb/l73ot4Ergwqr5vyDPa63ypgLzgJ2A3+d++wA/B44GZrT4PdwMnJHnfVfg2UqcwCbAglzuMOCNuXtci+v3WcAHqr9Pfwb38RFH/zgWODEi5kXE86SNwEH5FMILwPrAKyPixYiYFRHPDLK+h/Lf9QAi4vsR8VBELI2Iy4C7gO3rTRwRMyLiz3n8OaSN+782qO9w4JqIeBK4BNhb0gZV43w+Ip6IiPuBr5I2QJDmfyKwcUQsjojK9ZZ9gbsi4sKIWBIR04G/Uvtopqy3APdGxHdz2bcAV5ASbD1n5r3myudThWFLgVMi4vmIWJT73RwRP4iIpaS98J2Bj+R5nA18i3SURvX4hTIaORQ4IyLujoiFwMeAg6tOS50aEc81Ki8ifgusJ+lVOZ4Lqkap+z1ImgC8Hjg5z/uNpJ2giv8CfhoRP83zdS0wk5RIGpI0hbTMvt5sXCvHiaN/TCRdd3gqnw66HXiRdLHzQtJe3qWSHpL0BUmDPae7Sf77BICkwyTNLtT/GqpOKRRJ2kHS9ZLmS3qalPhqji9pDdIG92KAiLiZdH3nkKpRHyj8fx/pCAjSaQgBf5B0m6Qjc/+N83hUTbcJgzcR2KGYCEgb4pc3mOb9EfGywufkwrD5EbG4avzi/G4MPBERzxb6Vc9LcfxWVC+f+0hHBBuuQJkXAu8FdgOuqhrW6HvYGHgyIp6rGlYxEXhr1XLeBdioUTD5NObZwHGxAtd0rDEnjv7xAPDmqg3PqIh4MCJeiIjTImIr0mmDt7B8T3RFmz8+EHgMuEPSROB/SRuG9SPiZcBc0sa6Xh2XAD8CNo2IdUnXQVRjvEpd6wBnS3okn+ffhHQUUrRp4f8J5KOiSNdl3hkRG5NO252tdOvuQ6QND1XTPVgjhudIp/oqqhNA9Tw+ANxQ9X2sFRHvrjOPzdRahsV+D5H26tcu9Kuel7LfdfXymUA6ZfboCpR5IfAe0tHBP5rUU6nrQeBhYIyk0VXDKh4gnT4rLufREfG5JvGsA0wBLsvr0x9z/3mS3tDiPFkdThz945vAZ/JGHEnjJO2f/99N0mvzhclnSKdulubpHiWdw26J0kX195IuKH4snyYZTdqAzM/jvIN0xFHxKDBe0mqFfmuT9pAXS9qelx49FB0OfId0TWTb/NkZ2EbSawvjfVjSGEmbkq75XJbjeauk8XmcJ3OsS4GfAltIOiRf5H4bsBXwkxoxzAZ2lTQhX1D9WNXw6uX4k1z22yWNzJ/XK90sMOQi4gHgt8BnlW6GmAwcBbT0vEMd04EP5IvTawGnA5etyB56RNxDOhV5Yo3Bdb+HiLiPdOrpNEmrSdqFgacSLyKd0nqTpOF53qcWvu96niYdzWybP5VTW/8M/L7s/NlAThz942ukPfhfSHqWdKF8hzzs5cDlpKRxO3ADaQ+wMt1Bkp6UdGaD8p+S9BzwZ9KP7K0R8R2AiPgL8GXSRcxHSRv43xSm/RVwG/CIpMdzv/cAn8yxfgL4Xq1KJW0C7AF8NR85VD6zgJ8x8Kjjh8As0kb+auDbuf/rgd9LWpiX0XH5vP0C0tHX8aQLqicAb4mIx6mSz51fBszJdVQnlwHLMZ8y2ot0N9FDwCMsv7hdT+WurMpnVoNxa5lGusj7EOl00CkR8cuSZRR9h7Se3AjcAywG3reihUXETRHxUI3+zb6HQ0jr8hOkHZYLCtM+AOwPfJy04/IA8GGabLsiWbY+5WkBHo2I/wPIpzVLPxtloAi/yMnMzFrnIw4zMyvFicPMzEpx4jAzs1KcOMzMrJSVPnHku1davh3VlrV2O7Xbcaws1KSZcEnvVmqVeKEGNhY4VPUva3drqMuuqsdNnK8iupo4JN0r6f8kVTdqdkte0ScNto78UNbdgy1nqEk6L8978fbMW7sdVyvyU+TRaCMhaT1JV0l6TqkRvUMKw3aT9Of8JPCCPN5QPM3dFnk93bNNZY8ktdO0V15XFwxBmW2Ld2Ul6UuS7lJqaPGvkg6rGr6tpFmS/pH/blsY9mFJc/O090j6cNW0k5RaUfhHLrvhd9Oorjz8dZJu1PLXIBzXoKzdct1PS7q3xvBP5d/iEjVpiLSoF4447mF5m0MoPfC1Zv3RVypfiIHNbG9Ta6Rae4pl9x5bGV/SqyT9CjgT+JGkmZI2qxpnDOme+tuaFHcWqeXUDUlNcfyPpK3zsL8Ab8pPoG9MaveqpXdwtHuvuQt1bUhqtLDZ8nwJJb3wG14ZPEd68HBd0rNDX1NuwVfpwdYfkh5GHAOcD/xQyx94rbTsPAbYG3ivpIMLZU8HbiG1J3cicLmkcbWCaFZX3sn+GamR0/WBVwK/aDJf3yE9+1LL30jP1VzdoIyXii62sEhq/fUk4I+Ffl8iLdwAJuV++5IW/DOkB4BOLYz/NlLyqbQG+2bSw1iV1jOD1PgfwHmk9muuARaSHmJ7OanBvCdJDa9tVyh72bSF6T+d/59Kahn0BFLTHA+TWibdh9Ry6xPAxxvM+7KyagyblOs+itRm042kFmh/A3yF9BDVp0kr+QWkh5vuy8tyWC7jJeO38H38nPSg2ztJrZDuCGxYNc43SQ/3zaB+a6+jSUlji0K/C4HP1Rh3deCzwF+arCcfIT2c9zypPaUdSU9SPwXcCkwtjD8jl/mHvM78EFivMHw/0ob6qTzulg3qmk56Cn1RXmdOyOM1qn8z0kOYz5LebfINCq3SFsbbgvTDjlz2r3L/nUhNZDyd/+5UNW+fyd/tIgrrZ2E5D4i3sD4dntenx0kNZlamGQZ8FPh7Xle+V1xeNeLen/QQ5jN5mr0LsR1dKPMk0nr5GGk9XTcPG0XaMC7Iy++P5PWMtE5/m/R7epC0ng+vE8fqpN/uQ/nzVWD1qt/n8Sz/fb6jxLbpR8Dx+f+9ciwqDL+/Mt81pj0T+HrhO34eWLsw/NfAsXWmbVgX6en+C1udj0IZe5Ia5aw3/CIK29Wm5ZUNYCg/5GbDgTuALUlNgs8jtWtTTBxTadBEN6lxvPNIGfgh0lOplWHVieNxUrMDo0hPPN9D2lsYnlfS62tNW5i+mDiWkJ6KHkna2M4ntdG0NrA16ce7WZ15X1ZWjWGTqGrSmpQIlpCe7B2R+11A2iiunae5Ezgql1Fr/EOAOQ2+j9mko4MjKGwIC8O3JzUPMYzGiWM74B9V/T5Eoal0UntET5E2ci8ARzRZT2aT2qpag9aa2n6Q1CzKaFKrtZVmuisb6zfm7+0E0l7XarXqKq6nhXia1V+3mfAG33Wl+fZWmoK/n7R+jQBG1vtd1ajjf/Py24a0Mas0mX8cdZrsr7MOPJ3neVheFq8uxFZJHI2abG/0GoCrcv2jgQ1Iyf9ddWL5ZI57A2AcKZF/qur3+cn8Pe8D/AMY08J2aQ1SoqlsrD9Aarm5OM5PyImlqr9IO7nH5u4DgdurxvkGObHUmL5hXaRt1tfyvD6Wl+OEFuZppUwcJ5H2EPcm7aGNoJA4akz3VeArhe6XkX5MfwbOqRq3OnH8b2HY+4pfKik5PVVr2sL0xcSxiLw3RNp4B7BDYfxZ1HkHRS5rMWnjWfmcn4dNymW9ojD+EcD9he7hpL36rQr93sXydyAMGL/F7+Mw0pHSn0hHfpOq6psJ7Ji7Z1A/cbwBeKSq3zsrsVX1X4+0h79jk/XkyEL3R6ja6yIdLR1eiO1zhWFb5WU1HDgZ+F5h2DBSkplaq67ietpK/SxvKHB0YdgltJ443g78oWqcm8mJNc/bJ1v5XdWoY3yh3x+Ag/P/twN7FIZtRErmL3l3BWmj/pU69S5bJ4DrgPcUhr2qUiYpqfwWmFw1/YakhLZGod80CjtzVeP/Hdin0P0m8saR5b/PEYXhjzVazwrjnU86HVRpWeNk4NKqcS6mxoYWOI10BFo58nk78LuqcT4DnFen7oZ1kXYOnyI1szOKdHTzmxbmaUgTR6+cH72QtDd8BC9ty79pE90R8RTwfdIe5peb1FVs+XNRje61SsS9ICJeLExbq/xG5X0pBrb6eXjV8OomrYvdY0l7UtXNYq9wM9sRcQHpiO53pJZF/6zckCLp9NSciPhdC0UtJLVOWrQOac+7us4nWH4et9E1heK8TKR5U9vVTbCPJC2zAU18R2rE8QHKLbdG9TdrJryZVpqCL9t8esUjhf//wfJ1cyL1m+yvtilpg91Moybb670GYCLpe3q4EMs5pCOKVuvYuNC9IAY22Fic55okfZG0HfnPyFtUWlyflRoHPQzYN9I7c5pOW3VzzIQW6loEXBURf4zUDP9pwE6S1pX08UJZ32w0n4PVE4kjUguZ95AOJ6+sMUrDJrrzXQdHks5HN2rIr6x/0Lip7XaLBt2Ps/wFRhWDbWabiJhH2hs9lXQ+tfJ60j2AA7W82fOdgC+r9uto7wRGSNq80G8b6l8AHkHaOFT/YAaEVvi/laa2q5tgf4G0zAY08S1JedxGy626u1H9zZoJb6aVpuCbfa9lv/e6TfbXGfefWiizbpPtUf81AA+QjjjGFuJYJyK2ri68QR0vaWSxVUqv130z6Q634ovQbgMm53WlYjKF9VnpHTAfJR25zaua9hUa2Bz+st9CDLw55v4W6prDwO932f8RcXqhrGNLzXxJPZE4sqNIr8F8rsawuk10S6pcaPs46TWem0h6zxDFNBs4RKk5571p/Aa7jspHOt8jNbW+tlJz6x9kEM1sSzq8sIIPJ113qhxBHZG7t82fmaS9nZc0o52/wytJreOOlrQz6YLqhbmef893cA3Ld5ecAdySjz5a0UpT2/8laStJa5LOc19eWGb7Stoj7+UeT9pY/bZBfdVNqtetP5o3E95MmabgW423mbpN9tfwbeAdefkNk7SJpFfXGK9uk+2q8xqAiHiYdIfQlyWtk8v/J0n1fnfTgZNyvGNJ1xtXaP2X9DHSdmXPeOkt0TNIR2Dvl7R6PrKA/B52pRZ2TwfeGFW3/kfEnaTtyCl5PTmQlAiuqBNKw7qA75J24LbN6+/JpNc2P11nvoblbeTI1KlRhbvBUHodwChSLhiRhw+vE9uAGevah6pzsYX+A65xAAeRDkOfJf2Alt2lQrpr6JrCtNuQztNvnrurr3F8ujDusvci5+5XAksK3VNImf5Z0kZvOlV3VdWLOfe7CfivOvN+Hum8+8LC5/E8bBJV70em9nu9x5B+KJXmpj/BwLuqqsc/FLitwfdxOumC5vy8DH9Beh1rrXFnMPAd3B+v+h7WA35AuhB9P3BIYdj7SEeYz5FOn1wKTCyznpCa4b4hxzmfdDvhhEJsxbuqfkzai61MeyDpluCncxlbN6lr/zwPTwEfaqH+V5DunFlIg7uqGnzXu5Cujz2d/+5Sb7nXKXNAvHXqWFYOaaPxQdJNKs+STkWd3qD8A0l7vs/m9eVNdcr8BGm9nE++vTQPm5breo6U5M5k+TWedUm3Zs/L838L+VpMjTgq5/gfzp8zgVG1fp+NtjeF7cTzDPw9frwwfLv8XSwiXQMs3n15Dyn5Faf9ZtV3PCNPe0e9GFqpKw9/N+kI9EnSur1pg7Km5nkrforbvPNqDD+iUXwR4WbV7aUkHUG6kDajy6GsEEkzSBvqb3U7FrOVUS+dqjIzsz7QsadwrX9ExHndjsHMepdPVZmZWSldO1WVr97/QdKtSu/+Pa1bsZiZWeu6dsSR71MeHREL821lNwHHRYMHzMaOHRuTJk3qVIhmZiuFWbNmPR4RNRtWXBFdu8YRKWMtzJ0j86dhFps0aRIzZ85sd2hmZisVSWVaL2iq2+/jGC5pNqkNmWsj4vc1xjlGqXnvmfPnz+94jGZmNlBXE0dEvBgR25Ja5dxe0mtqjHNuREyJiCnjxg3ZkZaZma2gnniOI1IjhdeTWsc1M7Me1rVrHLmNohci4ilJa5Da9/98t+Ixs970wgsvMG/ePBYvXtztUHreqFGjGD9+PCNHjmxrPd18AHAj4PzcoNYw0jsSyjTkZmargHnz5rH22mszadIkBjYaa0URwYIFC5g3bx6bbbZZ8wkGoZt3Vc0hNeZlZlbX4sWLnTRaIIn111+fTtxE1BPXOMzMGnHSaE2nlpMTh5mZleJGDq2j7rpkMzY/5J5uh2F97K5Lhvb8fSvroyQOPfRQLroovSdqyZIlbLTRRuywww785CetX5qtPMQ8duzYFR5nv/324+6772bu3Lkt1zvUfMRhZtbE6NGjmTt3LosWLQLg2muvZZNNNmky1dC78sorWWuthq9N7wgnDjOzFuyzzz5cffXVAEyfPp1p06YtG/bEE09wwAEHMHnyZHbccUfmzJkDwIIFC9hrr73YeuutOfrooym2DXjRRRex/fbbs+222/Kud72LF198sWH9Cxcu5IwzzuCkk05qw9yV48RhZtaCgw8+mEsvvZTFixczZ84cdthhh2XDTjnlFLbbbjvmzJnD6aefzmGHHQbAaaedxi677MJtt93GgQceyP333w/A7bffzmWXXcZvfvMbZs+ezfDhw7n44osb1n/yySdz/PHHs+aaa7ZvJlvkaxxmZi2YPHky9957L9OnT2efffYZMOymm27iiiuuAGD33XdnwYIFPPPMM9x4441ceeWVAOy7776MGTMGgOuuu45Zs2bx+te/HoBFixaxwQYb1K179uzZ/P3vf+crX/kK9957bxvmrhwnDjOzFu2333586EMfYsaMGSxYsGCFy4kIDj/8cD772c+2NP7NN9/MzJkzmTRpEkuWLOGxxx5j6tSpzJgxY4VjGAyfqjIza9GRRx7JKaecwmtf+9oB/d/whjcsO9U0Y8YMxo4dyzrrrMOuu+7KJZdcAsA111zDk08+CcAee+zB5ZdfzmOPPQakayT33Ve/5fN3v/vdPPTQQ9x7773cdNNNbLHFFl1LGuAjDjPrM928nXv8+PG8//3vf0n/U089lSOPPJLJkyez5pprcv755wPp2se0adPYeuut2WmnnZgwYQIAW221FZ/+9KfZa6+9WLp0KSNHjuSss85i4sSJHZ2fFdVX7xyfMmVK+EVO/c3PcVhZt99+O1tuuWW3w+gbtZaXpFkRMWWo6vCpKjMzK8WJw8zMSnHiMLOe10+n1LupU8vJicPMetqoUaNYsGCBk0cTlfdxjBo1qu11+a4qM+tp48ePZ968eR15z0S/q7wBsN2cOMysp40cObLtb7SzcnyqyszMSnHiMDOzUpw4zPrYUL/UyKwVXUsckjaVdL2kv0i6TdJx3YrFzMxa180jjiXA8RGxFbAj8N+StupiPGZDykcDtrLqWuKIiIcj4k/5/2eB24HOv4vRzMxK6YlrHJImAdsBv68x7BhJMyXN9H3cZmbd1/XEIWkt4Arg/0XEM9XDI+LciJgSEVPGjRvX+QDNzGyAriYOSSNJSePiiLiym7GYmVlrunlXlYBvA7dHxBndisPMzMrp5hHHzsDbgd0lzc6ffZpNZGZm3dW1tqoi4iZA3arfzMxWTNcvjptZf/PzKqseJw4zMyvFicPMzEpx4jAzs1KcOMzMrBQnDus6X1y1Rrx+9B4nDjMzK8WJw8zMSnHiMDOzUpw4zMysFCcOMzMrxYnDWuI7W3qbvx/rJCcOsz7kRGHd5MRhfcUbTLPuc+IwM7NSnDjMhpiPimxl58RhZmalOHGYmVkpThxmZh3W76cznTjMzKyUriYOSd+R9Jikud2Mw2xl1O97tUPJy2JodfuI4zxg7y7HYGbWVitb4upq4oiIG4EnuhmDmZmV0+0jjqYkHSNppqSZ8+fP73Y4VsPKtjdlZo31fOKIiHMjYkpETBk3bly3wzEz64he3iHr+cRh1it6+Yc81FalebXynDhspXPXJZt1bMPnDaytirp9O+504GbgVZLmSTqqm/GYWf/qdhLvdv2d1O27qqZFxEYRMTIixkfEt7sZj3XeYH5sxWmH+ke7Km0EVkad/P5WxXXFp6p6xKq48tmqp1/X836Nu12cOMzMWuQEkoxoNoKkDYCdgY2BRcBcYGZELG1zbGZmfe2uSzZj80Pu6XYYQ65u4pC0G/BRYD3gFuAxYBRwAPBPki4HvhwRz3QgTjMz6xGNjjj2Ad4ZEfdXD5A0AngL8EbgijbFZqu4lXVvzaxav63rdRNHRHy4wbAlwA/aEZCZmfW2hhfHJQ2r6j5U0rGS1mxvWL2nclHMF8fMbFXX7K6qqyVtCSDpROAwYBvg0nYH1s+cXKzfeJ21MuomDkn/CmwOjMv/vx04h5Q0Xi1pV0kTOhOmmfU6J59VR9PbcUl3Uo0BXgQeB0S6LZf8v5mZrULqHnFExA3AJcBXgE8BX8ovXpoLPB4RN0bEfZ0J06y3uckTW5U0vMYREZ8ADgL2iYjvFqZ5Z7sD6yf+kXePl71Z5zW6xiGAiLg9Iv5W6R8R8yPi7uI4ZlaOE571s0ZHHNdLel/1BXBJq0naXdL5wOHtDc+q9dsGp9/itf7g9aq7GiWOvUkXxKdLekjSXyTdDdwFTAO+GhHndSDGlYJXdDNbWTS6OL44Is6OiJ2BicAewOsiYmJEvDMibulYlDaknMSsV3nd7A8tNaseES9ExMMR8VSb4zEzsyq9llD9Pg4Dem/F7KRVed7NVoQTh5mZldKskcPhkq7vVDBmZtb7mj0A+CKwVNK6HYrHzMynD3tcK21VLQT+LOla4LlKz4h4/2Arl7Q38DVgOPCtiPjcYMs0M7P2aiVxXJk/Q0rScOAs0lsE5wF/lPSjiPjLUNdlZlZWv72Vr5OaJo6IOF/SasAWudcdEfHCENS9PfC3QvMllwL7A04cNiT8wzdrk4ho+AGmAvcBNwA3AvcAuzabroVyDyKdnqp0vx34Ro3xjgFmAjMnTJgQg3HnxZMadg+loSx7Rcpq57x1w1DMz1B9/yvDsi3OQ+X/oZ6vVsvrpeXZS7EMJWBmDHKbXfy0cqrqy8BeEXEHgKQtgOnAPw9Z9mogIs4FzgWYMmVKdKJOM+scHxX2n1ae4xhZSRoAEXEnMHII6n4Q2LTQPT73MzOzHtbKEccsSd8CLsrdh5JOHQ3WH4HNJW1GShgHA4cMQbkt856OmVl5rSSOY4H/Biq33/4aOHuwFUfEEknvBX5Ouh33OxFx22DLNTOz9mqYOPIts7dGxKuBM4a68oj4KfDToS7XVj5DcXRYXYaPOAfy8rBWtfLk+B3VL3MyM7NVVyunqsYAt0n6AwOfHN+vbVGZmVnPaiVxnNz2KMzMrG+0co3jnHyNw8zMzNc4zMysHF/jMDOzUnyNo018a+PKy9+trerqJg5Jr46Iv0bEDZJWj4jnC8N27Ex4ZtZu7UqETrArr0bXOC4p/H9z1bBBPzluZmb9qVHiUJ3/a3WbWR/x0YANRqPEEXX+r9VtPcYbBjNrl0YXx8dLOpN0dFH5n9y9SdsjMzPrMO9wtaZR4vhw4f/qZtSHoll1MzPrQ3UTR0Sc38lAzMysP7TyBkAzM7NlnDjMzKwUJ44+4At2ZtZLGj05/nUa3HYbEe+vN8zMzFZejY44ZgKzgFHA64C78mdbYLW2R2ZmZj2p6V1Vkt4N7BIRS3L3N4FfdyY8MzPrNa1c4xgDrFPoXiv3W2GS3irpNklLJU0ZTFlmZtZZrTSr/jngFknXk54a3xU4dZD1zgX+HThnkOWYmVmHNU0cEfFdSdcAO+ReH4mIRwZTaUTcDiC5rUQzs37T9FSV0tZ9T2CbiPghsJqk7dse2fL6j5E0U9LM+fPnd6paMzOro5VrHGcD/wJMy93PAmc1m0jSLyXNrfHZv0yAEXFuREyJiCnjxo0rM6mZmbVBK9c4doiI10m6BSAinpTU9HbciNhz0NGZmVnPaeWI4wVJw8kPA0oaByxta1RmZtazWkkcZwJXARtI+gxwE3D6YCqVdKCkeaRTYFdL+vlgyjMzs85peKpK0jDgHuAEYA/S7bgHVO6KWlERcRUpGZmZWZ9pmDgiYqmksyJiO+CvHYrJzMx6WCunqq6T9B/yQxdmZkZrieNdwPeB5yU9I+lZSc+0OS4zM+tRrTw5vnYnAjEzs/7QynMcSBoDbE5qYh2AiLixXUGZmVnvapo4JB0NHAeMB2YDOwI3A7u3NTIzM+tJrVzjOA54PXBfROwGbAc81c6gzMysd7WSOBZHxGIASatHxF+BV7U3LDMz61WtXOOYJ+llwA+AayU9CdzXzqDMzKx3tXJX1YH531Pzy5zWBX7W1qjMzKxntXJxfEKh85789+XA/W2JyMzMelorp6quJrWMK9LtuJsBdwBbtzEuMzPrUa2cqnptsVvS64D3tC0iMzPraa3cVTVARPyJ5e8fNzOzVUwr1zg+WOgcBrwOeKhtEZmZWU9r5RpHsa2qJaRrHle0JxwzM+t1rVzjOK0TgZiZWX9o5VTVj8nvG68lIvYb0ojMzKyntXKq6m7ScxsX5e5pwKOkJ8nNzGwV00ri2DkiphS6fyxpZkR8oF1BmZlZ72rldtzRkl5R6ZC0GTB6MJVK+qKkv0qaI+mq3BaWmZn1gVYSxweAGZJmSLoBuJ7U1PpgXAu8JiImA3cCHxtkeWZm1iGt3FX1M0mbA6/Ovf4aEc8PptKI+EWh83fAQYMpz8zMOqfuEYek10t6OUBOFNsAnwS+KGm9IYzhSOCaBnEcI2mmpJnz588fwmrNzGxFNDpVdQ7wfwCSdgU+B1wAPA2c26xgSb+UNLfGZ//COCeSHiq8uF45EXFuREyJiCnjxo1rba7MzKxtGp2qGh4RT+T/3wacGxFXAFdImt2s4IjYs9FwSUcAbwH2iIi6z4mYmVlvaXTEMVxSJbHsAfyqMKyV23jrkrQ3cAKwX0T8YzBlmZlZZzVKANOBGyQ9DiwCfg0g6ZWk01WD8Q1gddKraAF+FxHHDrJMMzPrgLqJIyI+I+k6YCPgF4XTScOA9w2m0oh45WCmNzOz7ml4yikiflej353tC8fMzHpd6Rc5mZnZqs2Jw8zMSnHiMDOzUpw4zMysFCcOMzMrxYnDzMxKceIwM7NSnDjMzKyUVSpxbH7IPd0Owcys761SicPMzAbPicPMzEpx4jAzs1KcOMzMrBQnDjMzK8WJw8zMSnHiMDOzUpw4zMysFCcOMzMrxYnDzMxKceIwM7NSupI4JH1K0hxJsyX9QtLG3YjDzMzK69YRxxcjYnJEbAv8BPhEl+IwM7OSupI4IuKZQudoILoRh5mZlTeiWxVL+gxwGPA0sFuD8Y4BjgGYMGFCZ4IzM7O6FNGenX1JvwReXmPQiRHxw8J4HwNGRcQpzcqcMmVKzJw5cwijNDNb+UmaFRFThqq8th1xRMSeLY56MfBToGniMDOz7uvWXVWbFzr3B/7ajTjMzKy8bl3j+JykVwFLgfuAY7sUh5mZldSVxBER/9GNes3MbPD85LiZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWSlcTh6TjJYWksd2Mw8zMWte1xCFpU2Av4P5uxWBmZuV184jjK8AJQHQxBjMzK6kriUPS/sCDEXFrC+MeI2mmpJnz58/vQHRmZtbIiHYVLOmXwMtrDDoR+DjpNFVTEXEucC7AlClTfHRiZtZlbUscEbFnrf6SXgtsBtwqCWA88CdJ20fEI+2Kx8zMhkbbEkc9EfFnYINKt6R7gSkR8XinYzEzs/L8HIeZmZXS8SOOahExqdsxmJlZ63zEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalKKJ/HsaWNB+4rw1FjwX66TmSfoq3n2KF/oq3n2IFx9tujeKdGBHjhqqivkoc7SJpZkRM6XYcreqnePspVuivePspVnC87dbJeH2qyszMSnHiMDOzUpw4knO7HUBJ/RRvP8UK/RVvP8UKjrfdOhavr3GYmVkpPuIwM7NSnDjMzKyciOi7D7ApcD3wF+A24Ljcfz3gWuCu/HdM7n8oMAf4M/BbYJtCWXsDdwB/Az7aoM7Dc7l3AYfnfmsDswufx4Gvtjne7wCPAXObLKOa8wW8N/cLYGyPx/rrwrJ9CPhBu+KtV04vLtshirWTy3YU8Afg1lzOaWV+Z7n/Z4AHgIXt3i4MNl66sF3Iw4cDtwA/acfyHVBOKyP12gfYCHhd4Uu6E9gK+ELlxwF8FPh8/n+nwsJ/M/D7woL+O/AKYLW8omxVo771gLvz3zH5/zE1xpsF7NqueHP3rsDraLAxbjRfwHbAJOBeam/ceibWqvGuAA5r47pQs5xeXLZDEWuHl62AtfL/I4HfAzuW+Z0BO+Z4GiWOnom309uF3O+DwCXUSRyDXb4DymplpF7/AD8E3kjas9qo8KXcUWPcMcCD+f9/AX5eGPYx4GM1ppkGnFPoPgeYVjXOFqSMrXbFW+g3icYb46bzRZ2NW4/Gug7wJLBOu+OtLqeXl+0QxdrRZQusCfwJ2KHGsFZ+Zy1t2Hoo3o5sF0iv4L4O2J36iWPIlm/fX+OQNIm0p/d7YMOIeDgPegTYsMYkRwHX5P83IX2pFfNyv2qtjHcwcFnkpd+meFvV6nw11EOxHgBcFxHPdCLeqnJWJN6meijWA+jAspU0XNJs0qnLayOibcu2x+Lt1Hbhq8AJwNIG1QzZ8u36GwAHQ9JapMPs/xcRz0haNiwiQlJUjb8baYHv0oZwDgbe3miEHou3oR6LdRrwrUYjDFW81eUMTfg9HWtHlm1EvAhsK+llwFWSXhMRc1cw5oZ6LN62bxckvQV4LCJmSZq6AjGW1rdHHJJGkhb2xRFxZe79qKSN8vCNSHsLlfEnk34g+0fEgtz7QdIFqorxwIOSdpA0O3/2qzdeoextgBERMavN8dYre9NCvMc2i7eZXopV0lhge+Dqdsdbq5xeXbZDEWsnl21FRDxFuiC8d9nfWSt6Kd4Obhd2BvaTdC9wKbC7pIvasXyXaeV8Vq99SBevLqDqTgXgiwy8qPSF/P8E0l0lO1WNP4J0gWgzll883LpGfesB95DOK47J/69XGP45Gt95MSTxFqabROPrBk3ni/oXcHsqVuBY4PwOrAs1y+nFZTtUsXZw2Y4DXpb/X4N0R9dbyv7O8jiNLo73VLx0eLuQx5lK44vjK7x8B4zXyki99iEdogXp1rTZ+bMPsD7pAtFdwC8rC4WUoZ8sjDuzUNY+pLsZ/g6c2KDOI/OX9jfgHVXD7gZe3aF4pwMPAy+QzlEeVafOmvMFvD9Pt4R0G+a3ejXWPGwGsHe7l229cnpx2Q5FrB1etpNJt4nOAeYCnyj7OyPdaTSPdA5/HnBqL8fb6e1CocypNL4dd4WXb/HjJkfMzKyUvr3GYWZm3eHEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhVoekF/PDU7dJulXS8ZIa/mYkTZJ0SKdiNOsGJw6z+hZFxLYRsTWp8bk3A6c0mWYS4MRhKzU/x2FWh6SFEbFWofsVwB+BscBE4EJgdB783oj4raTfAVuSnso9HziT9ATxVGB14KyIOKdjM2HWBk4cZnVUJ47c7yngVcCzwNKIWCxpc2B6REzJjcx9KCLeksc/BtggIj4taXXgN8BbI+KeDs6K2ZDq69ZxzbpoJPANSdsCL5Leu1DLXsBkSQfl7nWBzUlHJGZ9yYnDrEX5VNWLpNZKTwEeBbYhXStcXG8y4H0R8fOOBGnWAb44btYCSeOAbwLfiHR+d13g4YhYSnrfwvA86rOk14BW/Bx4d24+G0lbSBqNWR/zEYdZfWsovQVuJKnF2wuBM/Kws4ErJB0G/Ax4LvefA7wo6VbgPOBrpDut/qT0hp75pLfumfUtXxw3M7NSfKrKzMxKceIwM7NSnDjMzKwUJw4zMyvFicPMzEpx4jAzs1KcOMzMrJT/D3B83ccWFxP1AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_label = 'Model 4'\n",
        "plt.bar(results_df.index, y4_diff, color='goldenrod', label=plot_label)\n",
        "plt.title(f'Test Data Error for {plot_label}.')\n",
        "plt.ylabel('Error ($)')\n",
        "plt.xlabel('Date')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
